{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision\n",
    "from transformer.Vision_transformer import VisionTransformer, CustomDataset\n",
    "import torchvision.transforms as transforms\n",
    "from pprint import pprint\n",
    "from torchsummary import summary\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CustomDataset(Dataset):\n",
    "#     \"\"\"Puts incoming MNIST dataset into an object \n",
    "#         which can be loaded onto cuda gpu.\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     data : torchvision.datasets.mnist.MNIST\n",
    "\n",
    "#     Attributes\n",
    "#     ----------\n",
    "#     X : torch.Tensor\n",
    "#         Shape `(n_samples, n_channels, img_height, img_width)`\n",
    "#     \"\"\"\n",
    "#     def __init__(self, data, device = device):\n",
    "#         self.X = torch.cat([torch.unsqueeze(data[i][0], dim=0) for i in range(len(data))], dim=0).to(device)\n",
    "#         self.Y = torch.tensor([data[i][1] for i in range(len(data))]).to(device)\n",
    "    \n",
    "#     def __len__(self):\n",
    "#         \"\"\"Length method.\n",
    "#         Parameters\n",
    "#         ----------\n",
    "#         None\n",
    "#         Returns\n",
    "#         ----------\n",
    "#         int\n",
    "#             n_samples\n",
    "\n",
    "#         \"\"\"\n",
    "#         return self.X.shape[0]\n",
    "    \n",
    "#     def __getitem__(self, idx):\n",
    "#         \"\"\"Indexing call.\n",
    "#         Parameters:\n",
    "#         idx : int\n",
    "#             index of element to be returned.\n",
    "        \n",
    "#         Returns : \n",
    "#         torch.Tensor\n",
    "#             Shape `(n_channels, img_height, img_width)`\n",
    "#         torch.Tensor\n",
    "#             Shape `(class_idx)`\n",
    "#         \"\"\"\n",
    "#         return self.X[idx], self.Y[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform = transforms.Compose([\n",
    "#     transforms.ToTensor(),\n",
    "# ])   # Transform object to apply on the dataset.\n",
    "\n",
    "# train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "# test_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "# # Loading/Downloading dataset. `download` can be `False` if the data is present in the root directory\n",
    "# # Else it will download the dataset to to the root location.\n",
    "\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# # Getting the device to compute on. `cuda` if GPU is available, else `cpu`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Convert PIL Image to tensor\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize the image tensors\n",
    "])\n",
    "\n",
    "# Load CIFAR-10 training dataset\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "# Load CIFAR-10 test dataset\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Classes in CIFAR-10 dataset\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = CustomDataset(data=train_dataset, device=device)\n",
    "test_ds = CustomDataset(data=test_dataset, device=device)\n",
    "# Made custom dataset objects from the MNIST dataset.\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_ds, batch_size=64, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_ds, batch_size=64, shuffle=False)\n",
    "# DataLoaders for fast implementation of loading batch-wise data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "CIFAR_ViT = VisionTransformer(\n",
    "    img_size=32,\n",
    "    patch_size=4,\n",
    "    in_chans=3,\n",
    "    n_classes=len(classes),\n",
    "    embed_dim=16,\n",
    "    depth=4,\n",
    "    n_heads=4,\n",
    "    mlp_ratio=1.0,\n",
    "    p=0.3,\n",
    "    attn_p=0.3\n",
    ").to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(CIFAR_ViT, (3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Loss criteria for multiclass classification task.\n",
    "optimizer = torch.optim.Adam(CIFAR_ViT.parameters(), lr=0.001)\n",
    "# Optimizer to update weights after calculating gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 150\n",
    "# Number of Epochs to run the following training loop for\n",
    "for epoch in range(num_epochs):\n",
    "    CIFAR_ViT.train()\n",
    "    # Setting the model in training mode\n",
    "    running_loss = 0.0  \n",
    "    # Parameter to store the total loss over dataset in the epoch. This has no role in training.\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        #loading images and labels to device. In our case, it is the cuda GPU device.\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = CIFAR_ViT(images)\n",
    "        # Predicting classes of the input batch.\n",
    "        loss = criterion(outputs, labels)\n",
    "        # Calculating loss of the predicted classes with the ground truth\n",
    "        loss.backward()\n",
    "        # Backpropagation step\n",
    "        optimizer.step()\n",
    "        # Updating the weights according to the optimizer's rules.\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        # Calculating the loss over the dataset\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, loader = test_loader):\n",
    "    correct, total = 0, 0\n",
    "    model.eval()\n",
    "    # Setting the model in evaluation mode.\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            # Loading batch images and ground truth onto device\n",
    "            outputs = model(images)\n",
    "            \n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        \n",
    "    return f\"Accuracy on test set: {(100 * correct / total):.2f}%\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(CIFAR_ViT, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    'model_state_dict': CIFAR_ViT.state_dict()\n",
    "}, \"cifar_model_86pct.pth\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "My_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
