{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Projects\\finetuner\\My_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision\n",
    "from Vision_transformer import CustomDataset\n",
    "from Vision_transformer import VisionTransformer\n",
    "import torchvision.transforms as transforms\n",
    "from pprint import pprint\n",
    "from torchsummary import summary\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device(\"cpu\")\n",
    "# We don't want to perform our quantization step on cuda GPU. It is not supported.\n",
    "with open('config.json') as f:\n",
    "    custom_config = json.load(f)\n",
    "# Custom configurations for the VisionTransformer.\n",
    "# Transformer can be customized with these configurations.\n",
    "# Refer to documentation of the class VisionTransformer\n",
    "# (`VisionTransformer.__doc__`, use pprint for cleaner display)\n",
    "# for exact details of the customization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load saved model\n",
    "MNIST_ViT = VisionTransformer(**custom_config).to(device=device)\n",
    "checkpoint = torch.load(\"model.pth\")\n",
    "MNIST_ViT.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VisionTransformer(\n",
       "  (patch_embed): PatchEmbed(\n",
       "    (proj): Conv2d(1, 32, kernel_size=(4, 4), stride=(4, 4))\n",
       "  )\n",
       "  (pos_drop): Dropout(p=0.2, inplace=False)\n",
       "  (blocks): ModuleList(\n",
       "    (0-1): 2 x Block(\n",
       "      (norm1): LayerNorm((32,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=32, out_features=96, bias=True)\n",
       "        (attn_drop): Dropout(p=0.2, inplace=False)\n",
       "        (proj): Linear(in_features=32, out_features=32, bias=True)\n",
       "        (proj_drop): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (norm2): LayerNorm((32,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): MLP(\n",
       "        (fc1): Linear(in_features=32, out_features=12, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (fc2): Linear(in_features=12, out_features=32, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (norm): LayerNorm((32,), eps=1e-06, elementwise_affine=True)\n",
       "  (head): Linear(in_features=32, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MNIST_ViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load saved model\n",
    "# MNIST_ViT_quant = VisionTransformerForPTQ(**custom_config).to(device=device)\n",
    "# checkpoint = torch.load(\"model.pth\")\n",
    "# MNIST_ViT_quant.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inp = torch.rand((1, 1, 28, 28)).to(device)\n",
    "# MNIST_ViT_quant(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# qconfig = torch.ao.quantization.get_default_qconfig('x86')\n",
    "max_bit_length = 4\n",
    "# net_quantized.qconfig = torch.ao.quantization.default_qconfig\n",
    "\n",
    "qconfig = torch.quantization.QConfig(\n",
    "    activation=torch.quantization.fake_quantize.FakeQuantize.with_args(observer = torch.quantization.observer.MovingAverageMinMaxObserver.with_args(dtype=torch.quint8), quant_min = 0 ,quant_max=2**(max_bit_length)-1, dtype=torch.quint8), \n",
    "    weight=torch.quantization.fake_quantize.FakeQuantize.with_args(observer = torch.quantization.observer.MovingAverageMinMaxObserver.with_args(dtype=torch.qint8), quant_min = 0 ,quant_max=2**(max_bit_length)-1, dtype=torch.qint8)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST_ViT_quant_fused = torch.ao.quantization.fuse_modules(MNIST_ViT_quant, [['linear', 'gelu'], ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function torch.ao.quantization.quantize.quantize_dynamic(model, qconfig_spec=None, dtype=torch.qint8, mapping=None, inplace=False)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ao.quantization.quantize_dynamic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a quantized model instance\n",
    "\n",
    "\n",
    "model_int8 = torch.ao.quantization.quantize_dynamic(\n",
    "    model = MNIST_ViT,\n",
    "    qconfig_spec = {qconfig}\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# model_int8 = torch.ao.quantization.quantize_dynamic(\n",
    "#     MNIST_ViT,  # the original model\n",
    "#     qconfig,\n",
    "#     {nn.Linear, nn.Conv2d, nn.LayerNorm, nn.GELU, nn.Parameter},  # a set of layers to dynamically quantize\n",
    "#     dtype=torch.qint8)  # the target dtype for quantized weights\n",
    "\n",
    "# run the model\n",
    "input_fp32 = torch.randn(1, 1, 28, 28)\n",
    "res = model_int8(input_fp32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CustomDataset(Dataset):\n",
    "#     \"\"\"Puts incoming MNIST dataset into an object \n",
    "#         which can be loaded onto cuda gpu.\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     data : torchvision.datasets.mnist.MNIST\n",
    "\n",
    "#     Attributes\n",
    "#     ----------\n",
    "#     X : torch.Tensor\n",
    "#         Shape `(n_samples, n_channels, img_height, img_width)`\n",
    "#     \"\"\"\n",
    "#     def __init__(self, data, device = device):\n",
    "#         self.X = torch.cat([torch.unsqueeze(data[i][0], dim=0) for i in range(len(data))], dim=0).to(device)\n",
    "#         self.Y = torch.tensor([data[i][1] for i in range(len(data))]).to(device)\n",
    "    \n",
    "#     def __len__(self):\n",
    "#         \"\"\"Length method.\n",
    "#         Parameters\n",
    "#         ----------\n",
    "#         None\n",
    "#         Returns\n",
    "#         ----------\n",
    "#         int\n",
    "#             n_samples\n",
    "\n",
    "#         \"\"\"\n",
    "#         return self.X.shape[0]\n",
    "    \n",
    "#     def __getitem__(self, idx):\n",
    "#         \"\"\"Indexing call.\n",
    "#         Parameters:\n",
    "#         idx : int\n",
    "#             index of element to be returned.\n",
    "        \n",
    "#         Returns : \n",
    "#         torch.Tensor\n",
    "#             Shape `(n_channels, img_height, img_width)`\n",
    "#         torch.Tensor\n",
    "#             Shape `(class_idx)`\n",
    "#         \"\"\"\n",
    "#         return self.X[idx], self.Y[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])   # Transform object to apply on the dataset.\n",
    "\n",
    "# train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "# Loading/Downloading dataset. `download` can be `False` if the data is present in the root directory\n",
    "# Else it will download the dataset to to the root location.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = CustomDataset(data=test_dataset)\n",
    "# Made custom dataset objects from the MNIST dataset.\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_ds, batch_size=64, shuffle=False)\n",
    "# DataLoaders for fast implementation of loading batch-wise data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Accuracy on test set: 95.49%'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test(model : VisionTransformer):\n",
    "    correct, total = 0, 0\n",
    "    model.eval()\n",
    "    # Setting the model in evaluation mode.\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            # Loading batch images and ground truth onto device\n",
    "            outputs = model(images)\n",
    "            \n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        \n",
    "    return f\"Accuracy on test set: {(100 * correct / total):.2f}%\"\n",
    "            \n",
    "test(MNIST_ViT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 95.49%\n"
     ]
    }
   ],
   "source": [
    "model_int8.eval()\n",
    "# Setting the model in evaluation mode.\n",
    "correct, total = 0, 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        # Loading batch images and ground truth onto device\n",
    "        outputs = model_int8(images)\n",
    "        # Calculating logits.\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        # Updated number of correct predictions and total predictions.\n",
    "\n",
    "print(f\"Accuracy on test set: {(100 * correct / total):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VisionTransformer(\n",
       "  (patch_embed): PatchEmbed(\n",
       "    (proj): Conv2d(1, 32, kernel_size=(4, 4), stride=(4, 4))\n",
       "  )\n",
       "  (pos_drop): Dropout(p=0.2, inplace=False)\n",
       "  (blocks): ModuleList(\n",
       "    (0-1): 2 x Block(\n",
       "      (norm1): LayerNorm((32,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=32, out_features=96, bias=True)\n",
       "        (attn_drop): Dropout(p=0.2, inplace=False)\n",
       "        (proj): Linear(in_features=32, out_features=32, bias=True)\n",
       "        (proj_drop): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (norm2): LayerNorm((32,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): MLP(\n",
       "        (fc1): Linear(in_features=32, out_features=12, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (fc2): Linear(in_features=12, out_features=32, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (norm): LayerNorm((32,), eps=1e-06, elementwise_affine=True)\n",
       "  (head): Linear(in_features=32, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.quantization.convert(model_int8, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Accuracy on test set: 95.49%'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(model_int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 cls_token Parameter containing:\n",
      "tensor([[[-0.0122, -0.1364, -0.0094, -0.0141,  0.0223,  0.0042,  0.0245,\n",
      "          -0.0475, -0.0308, -0.0016,  0.0057,  0.0205,  0.1222,  0.0767,\n",
      "          -0.0336,  0.0040, -0.0123, -0.0162, -0.4628,  0.0262,  0.0148,\n",
      "          -0.0054, -0.1923,  0.0093,  0.0606, -0.0081,  0.0104, -0.0111,\n",
      "           0.0501,  0.1046, -0.0188,  0.0386]]], requires_grad=True)\n",
      "1 pos_embed Parameter containing:\n",
      "tensor([[[-0.0122, -0.1364, -0.0094,  ...,  0.1046, -0.0188,  0.0386],\n",
      "         [-0.1002,  0.2293,  0.1266,  ..., -0.2201,  0.0879,  0.2167],\n",
      "         [ 0.1388,  0.2504,  0.1720,  ..., -0.0359,  0.2639,  0.1905],\n",
      "         ...,\n",
      "         [-0.3200,  0.4005,  0.3438,  ...,  0.2797, -0.2134,  0.1789],\n",
      "         [ 0.1282,  0.2640,  0.3549,  ...,  0.2232,  0.1646,  0.0010],\n",
      "         [-0.6103,  0.2312, -0.1634,  ...,  0.1081, -0.1291,  0.5354]]],\n",
      "       requires_grad=True)\n",
      "2 patch_embed.proj.weight Parameter containing:\n",
      "tensor([[[[ 9.8508e-02, -1.6454e-01, -1.0587e-01,  5.7849e-02],\n",
      "          [ 5.7368e-03,  1.1244e-01,  9.3835e-02,  2.8764e-01],\n",
      "          [-1.8462e-01,  8.6324e-02, -2.8885e-02,  2.9850e-01],\n",
      "          [-2.1216e-01, -2.0213e-01, -3.3993e-01, -3.6425e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.8553e-02,  3.1582e-01,  1.2331e-01,  4.3918e-01],\n",
      "          [-3.1045e-01, -3.5102e-02,  1.2066e-02,  5.4815e-02],\n",
      "          [-6.5735e-02,  2.9189e-02,  5.1786e-02,  9.8952e-03],\n",
      "          [ 4.7078e-02,  1.9497e-01,  1.2696e-01,  1.2059e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.6702e-01, -1.4295e-02, -1.8229e-01,  2.2014e-02],\n",
      "          [-1.6708e-01,  5.5129e-02, -1.7927e-01,  1.8484e-01],\n",
      "          [-2.5268e-02,  1.4035e-02, -8.4881e-02,  4.3245e-01],\n",
      "          [ 4.6601e-02, -8.0072e-02, -5.0797e-02,  4.1464e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.8921e-01,  2.4021e-01,  2.2549e-01,  1.5910e-01],\n",
      "          [-6.3668e-02,  3.1490e-03, -1.3112e-01, -3.2002e-01],\n",
      "          [-2.1168e-02, -3.2535e-01, -2.1249e-01, -2.5986e-01],\n",
      "          [-5.8033e-02,  1.8220e-01,  4.1205e-01, -1.0072e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.4969e-02,  1.6930e-01, -1.5076e-02,  1.9490e-01],\n",
      "          [ 8.3943e-02, -4.8572e-02, -2.6104e-01,  2.6281e-01],\n",
      "          [ 2.6818e-03, -8.3566e-02, -2.5162e-01,  3.8853e-01],\n",
      "          [-9.6465e-02, -1.5311e-01, -1.5500e-01,  5.5032e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.7340e-01, -5.2023e-03, -2.4676e-01,  1.3181e-01],\n",
      "          [-1.2168e-01,  8.8690e-02,  2.9479e-02,  2.7350e-01],\n",
      "          [-2.4811e-01,  7.8170e-02,  2.4861e-01, -3.2915e-02],\n",
      "          [ 3.9304e-02, -1.4136e-02, -1.2088e-01, -1.3018e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.4463e-01, -1.1520e-01, -8.5184e-02, -1.2912e-01],\n",
      "          [ 4.8133e-02,  5.2418e-02,  1.0743e-02, -4.6728e-02],\n",
      "          [ 1.4714e-01,  1.7788e-01,  3.4655e-01,  4.7897e-02],\n",
      "          [-1.2884e-01,  2.0417e-01,  1.9535e-01,  3.5501e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.9505e-01, -1.9855e-01, -3.3798e-01, -3.7044e-01],\n",
      "          [-3.6983e-03, -1.8147e-01, -1.1990e-01,  3.5492e-01],\n",
      "          [-4.6022e-01, -2.2440e-01,  1.7354e-01,  2.2778e-01],\n",
      "          [ 4.7912e-01,  4.4712e-01,  3.8919e-01,  3.4903e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.2519e-02, -9.3616e-02, -1.2925e-01, -2.1906e-01],\n",
      "          [ 2.0181e-01,  1.2521e-01, -1.7857e-01, -3.8602e-02],\n",
      "          [ 2.6158e-01,  3.3850e-02, -5.2311e-02,  1.3898e-01],\n",
      "          [-2.3160e-01, -1.5655e-01, -3.2001e-01,  1.2921e-01]]],\n",
      "\n",
      "\n",
      "        [[[-5.1126e-02, -8.1965e-02, -5.2810e-02,  2.0570e-01],\n",
      "          [ 1.1238e-02,  2.8274e-02,  2.7647e-02, -1.4767e-02],\n",
      "          [-3.5785e-02, -1.4478e-02,  6.4108e-02, -1.6523e-01],\n",
      "          [-1.2735e-01, -4.5090e-02,  1.5792e-01, -2.7239e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.3669e-01,  1.6919e-01,  6.9188e-02,  1.3500e-01],\n",
      "          [-7.2562e-02,  5.6483e-02,  2.3079e-01, -1.2732e-01],\n",
      "          [-1.9205e-01,  1.9884e-01,  2.6680e-01, -3.4308e-01],\n",
      "          [ 5.7785e-02,  1.8916e-01,  1.9773e-01,  3.0036e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.1935e-01,  7.3988e-02,  7.8323e-02,  2.7469e-02],\n",
      "          [ 1.2917e-01,  2.9511e-01,  4.2360e-01,  1.4568e-01],\n",
      "          [ 1.2802e-02, -8.8790e-02, -7.8041e-02,  2.1595e-02],\n",
      "          [-8.6665e-02, -6.9283e-02, -9.9945e-02,  1.6522e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.0837e-01,  1.8993e-01,  3.7995e-02,  1.2903e-01],\n",
      "          [-2.3812e-01, -1.1050e-01,  1.5619e-02,  1.1772e-01],\n",
      "          [-1.4358e-01,  9.3776e-02,  4.5960e-02,  1.6057e-01],\n",
      "          [ 2.1156e-01,  6.0525e-02, -5.9671e-02, -1.6941e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 3.8349e-02, -5.7763e-02, -1.1398e-01, -3.1797e-01],\n",
      "          [ 2.3968e-01,  9.0963e-03,  5.7536e-02, -3.4461e-02],\n",
      "          [ 1.4426e-01,  4.4976e-02,  4.4510e-02,  1.3026e-02],\n",
      "          [ 2.1435e-01, -7.3667e-02,  5.5423e-02, -1.7434e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.0311e-01, -1.5334e-01, -7.2286e-02, -8.5891e-02],\n",
      "          [-6.0427e-02,  9.0033e-03,  4.3549e-02,  3.6514e-02],\n",
      "          [ 1.3588e-01,  8.8195e-03, -5.2447e-02,  5.6142e-02],\n",
      "          [-3.8181e-01, -1.1855e-01, -2.1780e-01,  4.2125e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.7444e-01, -1.8422e-01, -2.8730e-01, -5.6898e-01],\n",
      "          [ 2.0151e-01, -7.1005e-02, -1.5941e-02, -3.4606e-01],\n",
      "          [-1.0972e-02, -1.3264e-01, -6.3037e-02, -2.3785e-01],\n",
      "          [ 3.3429e-01, -3.0666e-02,  1.4117e-01, -2.6470e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 9.4218e-02,  2.7864e-02, -9.4770e-02,  1.2451e-01],\n",
      "          [-5.5049e-02,  6.5233e-02, -2.6771e-01,  3.9007e-01],\n",
      "          [-3.0873e-01, -2.6711e-01, -4.3063e-01,  2.8447e-01],\n",
      "          [-5.9960e-01,  2.0703e-02, -2.2027e-01,  4.1495e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.3606e-02, -1.7572e-01, -8.9472e-03, -2.1892e-01],\n",
      "          [ 2.3239e-01,  1.5407e-01,  7.0519e-02, -4.8554e-02],\n",
      "          [ 5.4954e-03,  1.7057e-01,  1.8973e-01,  7.6907e-02],\n",
      "          [ 1.6758e-01,  6.3391e-02, -4.8491e-02,  1.0009e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.5844e-01, -1.7892e-01, -1.3343e-01, -1.2834e-01],\n",
      "          [ 1.6670e-01, -1.7056e-01, -8.8040e-02, -2.0386e-01],\n",
      "          [ 1.2753e-01, -3.1814e-01, -2.0180e-01, -1.8830e-01],\n",
      "          [ 1.5304e-01, -7.1549e-03, -1.0326e-01,  2.1620e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.3760e-01, -6.6828e-02,  8.3543e-02, -1.5592e-01],\n",
      "          [ 1.7243e-01, -1.4861e-01,  8.5817e-02, -2.2690e-01],\n",
      "          [ 1.6802e-01, -4.4844e-02, -1.3220e-01, -2.3911e-01],\n",
      "          [ 2.3258e-01,  1.2934e-01,  1.4171e-01,  3.9824e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.5733e-01,  2.0864e-01,  1.5330e-01,  4.8928e-02],\n",
      "          [-2.7295e-01,  5.5175e-02, -7.7545e-02, -9.9922e-02],\n",
      "          [-9.0327e-02, -8.1040e-02,  6.5454e-03, -4.7069e-02],\n",
      "          [-1.6896e-01,  6.3163e-02, -9.8137e-02,  3.4401e-02]]],\n",
      "\n",
      "\n",
      "        [[[-9.0480e-03, -2.5234e-02, -3.6739e-02,  1.4925e-01],\n",
      "          [-3.2313e-01, -2.4797e-01, -4.5005e-01, -2.9585e-01],\n",
      "          [ 7.0391e-02, -4.1590e-02, -1.4938e-01, -2.5660e-01],\n",
      "          [ 2.3439e-01,  1.0072e-02,  1.1774e-01,  5.2809e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.1381e-02, -1.1960e-02, -3.4939e-02, -1.6938e-01],\n",
      "          [-4.3448e-03,  1.0542e-01,  1.1818e-01, -3.8477e-02],\n",
      "          [ 6.8355e-02,  5.2448e-02, -1.6414e-01, -1.9519e-01],\n",
      "          [-1.4634e-01, -2.0461e-01, -4.0016e-01,  1.2440e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 6.0814e-02,  1.0819e-01,  1.7581e-01,  3.3928e-01],\n",
      "          [-1.3463e-01, -6.0941e-02, -7.6658e-02,  4.8418e-01],\n",
      "          [-2.9681e-02, -1.0244e-01, -1.7165e-01,  4.9518e-01],\n",
      "          [-2.6445e-01, -1.7119e-01, -2.5313e-01,  1.3256e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.3480e-01, -1.1863e-01,  1.0350e-01, -1.1969e-01],\n",
      "          [ 1.7646e-02,  2.8067e-02,  5.4899e-02,  8.1017e-03],\n",
      "          [ 7.5717e-02,  4.0198e-02,  2.6960e-01, -1.1236e-01],\n",
      "          [ 1.3544e-02, -5.6327e-02, -2.7678e-01, -4.1516e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.5575e-01, -2.4565e-02,  2.4260e-03, -2.5052e-01],\n",
      "          [-3.2385e-03,  1.1650e-02,  1.5548e-02, -1.4521e-03],\n",
      "          [-2.3827e-01, -2.7999e-02, -6.4678e-02, -2.5302e-01],\n",
      "          [-7.8783e-04,  6.4211e-02,  1.2739e-01,  1.4718e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.0271e-01, -1.0717e-01, -1.1436e-01,  2.4034e-01],\n",
      "          [ 2.4130e-02,  2.0796e-02, -1.6677e-01,  2.0191e-01],\n",
      "          [ 1.5908e-01,  2.0224e-01,  3.1105e-01,  2.6468e-01],\n",
      "          [-2.8374e-02, -1.5716e-01,  1.0709e-02, -3.3861e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.0713e-01,  3.2985e-01,  3.3700e-01,  3.4059e-01],\n",
      "          [ 3.3688e-01,  2.5634e-01,  2.9317e-02,  4.0933e-02],\n",
      "          [ 1.8216e-01, -8.8761e-02, -6.6401e-03, -2.0652e-02],\n",
      "          [-5.1194e-02, -2.2039e-01, -2.2058e-02, -5.3697e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0138e-02,  1.8167e-01,  1.7393e-01,  8.9308e-02],\n",
      "          [-1.4578e-01,  3.8979e-02, -1.4216e-01,  1.4805e-02],\n",
      "          [-1.3634e-01, -6.1156e-03,  4.4406e-02, -8.6780e-02],\n",
      "          [-5.7867e-02, -2.8947e-01, -2.9683e-01, -3.9659e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 8.7554e-02,  5.4145e-02,  2.7641e-01, -3.4538e-01],\n",
      "          [ 2.5708e-01,  9.2645e-02,  8.9001e-02,  1.3893e-01],\n",
      "          [ 2.6357e-01, -3.2158e-02, -8.2594e-02,  1.2370e-01],\n",
      "          [ 1.1900e-01,  8.3982e-04, -1.1012e-02,  1.6646e-01]]],\n",
      "\n",
      "\n",
      "        [[[-5.5483e-02, -2.0205e-02,  1.8436e-04,  6.8521e-02],\n",
      "          [-1.2130e-01, -1.6792e-01, -1.4022e-01, -4.3008e-02],\n",
      "          [-1.5084e-01, -7.0904e-02,  1.5942e-01, -6.9582e-02],\n",
      "          [ 5.0601e-01,  2.7529e-01,  2.7099e-01, -5.1742e-01]]],\n",
      "\n",
      "\n",
      "        [[[-7.7916e-03, -4.7438e-02,  1.3850e-01, -7.6883e-02],\n",
      "          [ 1.3774e-01,  1.5530e-02,  4.6466e-02,  3.9620e-02],\n",
      "          [ 5.2241e-02, -1.3082e-01, -3.4331e-02, -2.5024e-02],\n",
      "          [ 1.1675e-01,  8.9918e-02,  1.7768e-01,  4.9570e-02]]]],\n",
      "       requires_grad=True)\n",
      "3 patch_embed.proj.bias Parameter containing:\n",
      "tensor([ 0.0704, -0.0958,  0.0960, -0.1136, -0.0455,  0.1074, -0.0340, -0.0641,\n",
      "         0.1232,  0.1210,  0.0131, -0.0042, -0.1069, -0.0412,  0.1474,  0.2029,\n",
      "         0.1472, -0.1134,  0.1594,  0.0341, -0.0956,  0.0933,  0.1182,  0.0873,\n",
      "         0.1009,  0.0542, -0.0135, -0.1961, -0.0439, -0.2220,  0.0725, -0.0467],\n",
      "       requires_grad=True)\n",
      "4 blocks.0.norm1.weight Parameter containing:\n",
      "tensor([0.8028, 0.6435, 0.7784, 1.0782, 0.9507, 0.9770, 0.9585, 0.6884, 0.8810,\n",
      "        0.8946, 1.0187, 0.8027, 0.6557, 0.9335, 0.7398, 0.6996, 0.5787, 1.0142,\n",
      "        0.6749, 0.8042, 1.0120, 0.8335, 0.7414, 0.7783, 0.8870, 0.9532, 0.7182,\n",
      "        0.6576, 0.7937, 0.7037, 0.9637, 0.8184], requires_grad=True)\n",
      "5 blocks.0.norm1.bias Parameter containing:\n",
      "tensor([ 0.0806, -0.0461, -0.0847,  0.0948, -0.0193,  0.0093, -0.0345,  0.0653,\n",
      "         0.0010, -0.0307,  0.0376, -0.1875,  0.0772,  0.0402, -0.0574,  0.0606,\n",
      "        -0.1304, -0.0254,  0.0138, -0.0916,  0.0589,  0.0082,  0.0370, -0.0547,\n",
      "         0.0179, -0.0108,  0.0143, -0.0682,  0.1235,  0.0948, -0.0655,  0.0040],\n",
      "       requires_grad=True)\n",
      "6 blocks.0.attn.qkv.weight Parameter containing:\n",
      "tensor([[-0.6157,  0.1359, -0.3927,  ..., -0.0914, -0.1215, -0.0668],\n",
      "        [-0.0548,  0.0630,  0.3043,  ...,  0.0437,  0.1184, -0.0048],\n",
      "        [-0.0569,  0.0738, -0.0500,  ..., -0.2929,  0.0228, -0.1211],\n",
      "        ...,\n",
      "        [-0.1001, -0.1904, -0.0895,  ...,  0.0732, -0.0094,  0.4558],\n",
      "        [ 0.1911,  0.1628, -0.1856,  ..., -0.1474, -0.1091, -0.1642],\n",
      "        [ 0.0961, -0.0473, -0.1628,  ..., -0.2397, -0.1357, -0.0134]],\n",
      "       requires_grad=True)\n",
      "7 blocks.0.attn.qkv.bias Parameter containing:\n",
      "tensor([ 7.4507e-02,  5.2139e-02, -4.8534e-01, -9.8150e-02,  1.4309e-01,\n",
      "        -4.5419e-01, -4.0607e-01, -3.4089e-01, -4.5833e-01, -4.2149e-01,\n",
      "         7.5312e-01,  1.1982e-01, -3.1671e-01, -2.4060e-01,  3.2204e-01,\n",
      "         3.6732e-01,  5.1658e-01, -6.1340e-02, -9.1437e-03,  2.1246e-01,\n",
      "         7.5220e-02, -5.5866e-01, -2.4227e-01,  3.0989e-02, -1.0168e-01,\n",
      "        -2.5245e-01,  4.6506e-01, -4.6430e-01,  5.0252e-01,  3.0739e-01,\n",
      "         3.0603e-02, -2.0222e-01, -1.3067e-01, -1.5128e-01, -3.4830e-02,\n",
      "        -1.2728e-01, -7.4746e-02,  1.7766e-01,  9.2772e-02, -1.4516e-01,\n",
      "        -1.8100e-01,  1.4847e-01,  1.2484e-01, -3.3221e-02,  2.5214e-02,\n",
      "         1.4210e-01, -1.4592e-01, -4.8739e-04,  3.0039e-02,  2.2110e-02,\n",
      "         5.1880e-02, -8.3391e-02,  1.5203e-01,  5.9182e-02, -5.6585e-02,\n",
      "        -1.1340e-01,  7.5753e-02, -8.0926e-02, -1.0791e-01, -2.6689e-02,\n",
      "        -9.5678e-02, -7.6443e-02,  1.5617e-01,  1.7518e-01,  1.2988e-01,\n",
      "        -1.5497e-01, -1.1162e-01, -1.6506e-01, -2.5490e-02, -1.2107e-01,\n",
      "         1.9446e-01, -5.0622e-03,  8.7188e-02, -3.7389e-03, -3.3297e-02,\n",
      "        -8.8440e-02,  6.8180e-02, -2.8350e-02,  3.3363e-02, -1.3584e-01,\n",
      "         1.3060e-02, -4.5568e-02,  1.1397e-02, -7.6570e-02,  3.2440e-02,\n",
      "        -7.5963e-02,  1.0069e-01,  3.7141e-02, -1.5183e-01, -1.0107e-02,\n",
      "         3.7132e-02,  4.5666e-02,  1.6060e-01, -2.2404e-02, -5.1604e-02,\n",
      "        -1.4338e-02], requires_grad=True)\n",
      "8 blocks.0.attn.proj.weight Parameter containing:\n",
      "tensor([[ 0.1311,  0.0185, -0.1605,  ..., -0.0595,  0.2479, -0.2342],\n",
      "        [ 0.0326, -0.1274, -0.1007,  ..., -0.2089, -0.1152,  0.0115],\n",
      "        [-0.2074, -0.2478, -0.0830,  ...,  0.0765, -0.0896, -0.3899],\n",
      "        ...,\n",
      "        [ 0.0393,  0.2791,  0.0637,  ...,  0.1395, -0.2090,  0.2195],\n",
      "        [-0.2204,  0.0586, -0.2772,  ...,  0.1143, -0.2222, -0.1691],\n",
      "        [-0.0275,  0.0048, -0.0972,  ...,  0.0453,  0.0188, -0.0676]],\n",
      "       requires_grad=True)\n",
      "9 blocks.0.attn.proj.bias Parameter containing:\n",
      "tensor([ 0.1003, -0.0709,  0.0421, -0.0358,  0.0579, -0.0020, -0.0769,  0.1425,\n",
      "        -0.0112, -0.0567, -0.1276,  0.0237,  0.0521, -0.0545,  0.1332, -0.0764,\n",
      "         0.0351, -0.0605, -0.1354, -0.0866,  0.0393,  0.0177,  0.0348,  0.1743,\n",
      "        -0.0002,  0.0340, -0.0327,  0.1045,  0.0239, -0.0197,  0.0231,  0.0218],\n",
      "       requires_grad=True)\n",
      "10 blocks.0.norm2.weight Parameter containing:\n",
      "tensor([0.8340, 0.7879, 1.0940, 0.9377, 1.0825, 0.8377, 1.0440, 1.0277, 0.9114,\n",
      "        0.9482, 0.7378, 1.0467, 0.9812, 1.0149, 0.9597, 1.0450, 0.8403, 0.9026,\n",
      "        0.8345, 0.8893, 0.8761, 0.9655, 0.7507, 0.9669, 0.8203, 1.0331, 0.9013,\n",
      "        0.9361, 0.8041, 0.9222, 0.8752, 1.0068], requires_grad=True)\n",
      "11 blocks.0.norm2.bias Parameter containing:\n",
      "tensor([ 0.0540,  0.0164,  0.2355, -0.1426,  0.0401,  0.1178,  0.0684,  0.1454,\n",
      "         0.0656,  0.2436,  0.0279,  0.1417,  0.1647, -0.0904,  0.0457, -0.1280,\n",
      "         0.0222, -0.0365, -0.0489, -0.0672, -0.0678, -0.1821,  0.0874,  0.1974,\n",
      "        -0.2027, -0.1363,  0.0220,  0.0502, -0.0982, -0.0536, -0.0912, -0.0898],\n",
      "       requires_grad=True)\n",
      "12 blocks.0.mlp.fc1.weight Parameter containing:\n",
      "tensor([[-0.2059,  0.1344, -0.1839,  0.4697,  0.0216, -0.0839, -0.3724, -0.0497,\n",
      "         -0.1632,  0.1081, -0.1453,  0.1279, -0.1121, -0.3249, -0.2738, -0.0046,\n",
      "          0.3463, -0.2539,  0.0119,  0.0570,  0.3042,  0.2603, -0.1928, -0.1277,\n",
      "          0.2174, -0.2015, -0.1354,  0.1322,  0.1614,  0.0277, -0.0392,  0.0628],\n",
      "        [ 0.0082, -0.1270,  0.0379, -0.1055,  0.2248, -0.0442, -0.1270, -0.0226,\n",
      "          0.0860, -0.1774,  0.1153, -0.2519, -0.4275,  0.1619,  0.1780,  0.1645,\n",
      "          0.1400, -0.0699,  0.1114,  0.1022,  0.1474,  0.1573,  0.1232, -0.0242,\n",
      "          0.1677,  0.0663,  0.1491, -0.1034,  0.0984, -0.2747,  0.0631, -0.1509],\n",
      "        [-0.0613,  0.0864, -0.2479,  0.1742, -0.3920,  0.0616, -0.2166, -0.1571,\n",
      "         -0.2779, -0.1418, -0.0113, -0.0257,  0.1582,  0.1854, -0.2192,  0.1009,\n",
      "         -0.1091,  0.2436, -0.0920, -0.1480,  0.0935, -0.1025, -0.0931, -0.1640,\n",
      "         -0.1786, -0.2468, -0.1921,  0.1893,  0.0383,  0.3511,  0.0848,  0.1665],\n",
      "        [-0.2926,  0.1517,  0.1194,  0.0757,  0.0943, -0.2653,  0.0171,  0.3073,\n",
      "         -0.1366, -0.3087,  0.1370, -0.5044,  0.0919, -0.0406, -0.0583,  0.0040,\n",
      "         -0.1060, -0.0743,  0.0774,  0.0815,  0.1808,  0.4184,  0.0582, -0.1950,\n",
      "         -0.0287,  0.1775, -0.2231, -0.2389, -0.1081, -0.1142,  0.1214,  0.0526],\n",
      "        [-0.1473, -0.1794, -0.1771,  0.1634,  0.1862, -0.2318,  0.2329,  0.1363,\n",
      "          0.1742, -0.2610,  0.0617,  0.1682, -0.1994,  0.1734,  0.0640, -0.0359,\n",
      "         -0.0898, -0.0735,  0.0041,  0.3424, -0.0785, -0.1362, -0.0999, -0.1859,\n",
      "         -0.0465,  0.2075,  0.1664,  0.0435, -0.0433,  0.1570,  0.0604,  0.2076],\n",
      "        [ 0.0785, -0.0422,  0.0133,  0.0206, -0.0276,  0.1500, -0.1608, -0.1755,\n",
      "          0.2429, -0.2170,  0.1328, -0.0747,  0.0682, -0.0561,  0.2059,  0.2374,\n",
      "          0.1436,  0.0814, -0.2793, -0.2256, -0.2996,  0.1230,  0.0170,  0.0800,\n",
      "          0.1703,  0.2229, -0.0838, -0.1646,  0.3716, -0.0233, -0.2675,  0.1775],\n",
      "        [ 0.1518, -0.1212, -0.1043, -0.2299,  0.0574, -0.2277, -0.3058, -0.1616,\n",
      "          0.2092, -0.2489, -0.3868,  0.0769,  0.0059,  0.3013, -0.0861,  0.0516,\n",
      "         -0.0429,  0.0888,  0.2080,  0.0571,  0.0506,  0.2269, -0.1077, -0.1523,\n",
      "          0.1847, -0.1470, -0.2796,  0.0980,  0.0951,  0.1357,  0.1729,  0.2075],\n",
      "        [-0.0686, -0.1963, -0.3646, -0.0758,  0.0207, -0.0782, -0.1539, -0.1276,\n",
      "          0.1548,  0.0633,  0.1350,  0.0435,  0.0523,  0.1437, -0.2433,  0.3254,\n",
      "         -0.1733,  0.0858,  0.1160,  0.2008, -0.1581,  0.0569, -0.0449, -0.4777,\n",
      "          0.2606, -0.0781,  0.0662,  0.1234,  0.0974, -0.0236,  0.0513,  0.0902],\n",
      "        [-0.0712, -0.1062,  0.1962,  0.0928, -0.0252,  0.2331,  0.2001,  0.0690,\n",
      "         -0.1196,  0.0235, -0.0151, -0.1659, -0.1314,  0.1100,  0.0498,  0.4481,\n",
      "         -0.1552,  0.1412, -0.0090,  0.0593,  0.0111,  0.1353,  0.3283, -0.0843,\n",
      "          0.1941,  0.1192,  0.1649, -0.1073,  0.0285,  0.0789,  0.2201, -0.1493],\n",
      "        [ 0.2456,  0.0113, -0.6227, -0.0273,  0.0823, -0.0114, -0.2620, -0.4350,\n",
      "          0.0450,  0.2472, -0.0349, -0.0357,  0.1138, -0.0551, -0.1248, -0.1277,\n",
      "         -0.1659,  0.0533, -0.1068, -0.1477,  0.0571, -0.0851,  0.0301,  0.1060,\n",
      "          0.1814, -0.1143, -0.0486,  0.2785, -0.0567, -0.0813, -0.0345,  0.2362],\n",
      "        [ 0.0805,  0.1362, -0.0210,  0.1700,  0.1190, -0.1027, -0.1586, -0.0209,\n",
      "         -0.1211, -0.1732,  0.1011, -0.2371,  0.0673, -0.0028, -0.2229,  0.0302,\n",
      "          0.1547, -0.2671,  0.2169,  0.0360, -0.1778,  0.0831, -0.1278,  0.0234,\n",
      "          0.1686,  0.4048, -0.0611, -0.1650,  0.1732, -0.1268, -0.0027, -0.1707],\n",
      "        [-0.1280, -0.2687,  0.0482,  0.2244, -0.3753, -0.0677, -0.0028,  0.2029,\n",
      "         -0.0899, -0.2278, -0.0430, -0.3991, -0.1549,  0.2054, -0.0655, -0.1509,\n",
      "         -0.1044,  0.3017,  0.1998, -0.0942, -0.0774,  0.1908, -0.0898, -0.1570,\n",
      "         -0.1135,  0.1559,  0.1383, -0.3049, -0.0445,  0.1037, -0.2750,  0.2667]],\n",
      "       requires_grad=True)\n",
      "13 blocks.0.mlp.fc1.bias Parameter containing:\n",
      "tensor([-0.0379, -0.1989, -0.2930, -0.2983, -0.1813, -0.2350, -0.0520,  0.1186,\n",
      "        -0.1101, -0.3205, -0.0584, -0.2649], requires_grad=True)\n",
      "14 blocks.0.mlp.fc2.weight Parameter containing:\n",
      "tensor([[ 0.4515,  0.3438, -0.1474,  0.2759, -0.0201, -0.1704,  0.0052,  0.2981,\n",
      "          0.2650, -0.3306, -0.2310, -0.0250],\n",
      "        [-0.1595,  0.0323, -0.0854,  0.1792,  0.0227, -0.2989, -0.2186,  0.1391,\n",
      "          0.2883,  0.5339, -0.2111, -0.1802],\n",
      "        [ 0.1312, -0.0433, -0.0731, -0.1400,  0.1882, -0.2104, -0.3622, -0.1504,\n",
      "          0.0464,  0.3631, -0.3010, -0.0455],\n",
      "        [-0.6444,  0.3364,  0.2742, -0.0358, -0.3252,  0.1017,  0.2726,  0.4481,\n",
      "          0.1149, -0.1650,  0.1069,  0.0443],\n",
      "        [-0.0256, -0.1847,  0.1978, -0.1537, -0.3040, -0.0668,  0.3183,  0.3663,\n",
      "          0.2945, -0.3349, -0.1642, -0.0622],\n",
      "        [-0.3397, -0.0844,  0.1653,  0.2532,  0.0658, -0.2675, -0.4699,  0.0226,\n",
      "         -0.3154, -0.1450, -0.1177, -0.3172],\n",
      "        [-0.1309, -0.4475,  0.6556,  0.3264,  0.2736, -0.0657,  0.0086,  0.0671,\n",
      "         -0.1494,  0.1711,  0.0794, -0.4562],\n",
      "        [-0.1247, -0.1135, -0.0706, -0.3005, -0.0028,  0.0541,  0.6781,  0.1511,\n",
      "          0.2846,  0.3961, -0.1776, -0.3369],\n",
      "        [-0.1457, -0.0658, -0.1340,  0.3714,  0.0619, -0.1591, -0.4584,  0.0931,\n",
      "          0.3551,  0.2650,  0.5257,  0.0677],\n",
      "        [ 0.3180,  0.1198,  0.2347,  0.3142,  0.2441,  0.0752,  0.0399,  0.2092,\n",
      "          0.3422, -0.2206,  0.0957, -0.1888],\n",
      "        [ 0.0113, -0.3790,  0.0819, -0.0334,  0.0864,  0.3669,  0.1089,  0.6666,\n",
      "         -0.0419, -0.1692, -0.6812, -0.3281],\n",
      "        [ 0.3018,  0.1292,  0.1873,  0.3139, -0.2693, -0.2195,  0.2244,  0.1006,\n",
      "         -0.3194, -0.1264,  0.0247,  0.0170],\n",
      "        [-0.0726,  0.3203,  0.3524,  0.1885,  0.2897, -0.0086,  0.0214, -0.1309,\n",
      "         -0.1221,  0.1326,  0.4928, -0.1722],\n",
      "        [ 0.1748, -0.3237, -0.1709,  0.2859,  0.0345,  0.0525, -0.2781, -0.1097,\n",
      "          0.0321,  0.3391, -0.3413,  0.5300],\n",
      "        [ 0.1902,  0.0077,  0.0456,  0.0230,  0.3882, -0.2266, -0.1188, -0.3516,\n",
      "          0.3416, -0.1391,  0.1933, -0.2831],\n",
      "        [ 0.0914, -0.3193, -0.2547, -0.1327, -0.0868, -0.1509, -0.3838, -0.2305,\n",
      "          0.0851,  0.2456, -0.0516,  0.0170],\n",
      "        [-0.2309,  0.2300,  0.1265, -0.3100, -0.3507,  0.2580, -0.2199,  0.0054,\n",
      "          0.2065, -0.3838, -0.1518,  0.3083],\n",
      "        [-0.1167,  0.0890,  0.1203,  0.0537, -0.0395,  0.0648, -0.0035, -0.1746,\n",
      "          0.0779,  0.1736,  0.0783,  0.6006],\n",
      "        [ 0.0300, -0.1391, -0.1555, -0.2934, -0.2994,  0.0642, -0.3236,  0.1502,\n",
      "          0.1327, -0.0747, -0.1209,  0.4594],\n",
      "        [-0.1066,  0.3050,  0.4355,  0.0732, -0.3322, -0.1585,  0.1400, -0.3600,\n",
      "          0.2072, -0.1668,  0.2531, -0.1298],\n",
      "        [ 0.0267, -0.3940, -0.1732, -0.4057,  0.4457,  0.1030, -0.3269, -0.0207,\n",
      "         -0.1292, -0.0017, -0.4243,  0.4166],\n",
      "        [-0.0188, -0.0181,  0.4368, -0.2039, -0.3579,  0.3522,  0.1199, -0.1614,\n",
      "         -0.1138,  0.2088, -0.0993,  0.3020],\n",
      "        [ 0.2818,  0.2804, -0.1744, -0.0735,  0.5124,  0.3055,  0.0187, -0.3184,\n",
      "         -0.3437, -0.1604,  0.0709, -0.2144],\n",
      "        [ 0.1064,  0.2671,  0.1543, -0.1417, -0.1003, -0.3056,  0.2919,  0.2772,\n",
      "         -0.2699, -0.0023, -0.1212,  0.3031],\n",
      "        [ 0.0417, -0.1154,  0.0667,  0.0083,  0.2706, -0.3167, -0.1297,  0.0776,\n",
      "         -0.1519, -0.1267, -0.1078, -0.2074],\n",
      "        [-0.4242, -0.0295,  0.6543,  0.0352, -0.5353, -0.1908,  0.4431,  0.1121,\n",
      "         -0.2913, -0.2025, -0.2469,  0.0036],\n",
      "        [ 0.2303,  0.3616, -0.1852,  0.6359,  0.0756, -0.2406, -0.5596, -0.2694,\n",
      "          0.1373,  0.5969,  0.2876, -0.3990],\n",
      "        [ 0.1713,  0.2252, -0.0121,  0.2362, -0.0773,  0.2629, -0.1502,  0.1371,\n",
      "          0.0616, -0.4175,  0.0869,  0.0329],\n",
      "        [ 0.1486, -0.1410, -0.3800,  0.2303,  0.0114, -0.3337,  0.0584, -0.3398,\n",
      "         -0.0814,  0.2321,  0.0527, -0.1978],\n",
      "        [ 0.1494, -0.1054, -0.8103, -0.3863,  0.2437,  0.0956,  0.1931,  0.1680,\n",
      "          0.4117, -0.0523,  0.0118,  0.3482],\n",
      "        [-0.1744,  0.2673, -0.2232, -0.3332, -0.2039,  0.3026,  0.4011, -0.3532,\n",
      "         -0.2273,  0.3089,  0.0017,  0.4026],\n",
      "        [-0.0496,  0.3825,  0.0776, -0.3974, -0.0673,  0.3955,  0.2510,  0.1775,\n",
      "          0.2903, -0.0021,  0.1925,  0.0488]], requires_grad=True)\n",
      "15 blocks.0.mlp.fc2.bias Parameter containing:\n",
      "tensor([-0.0338, -0.3155,  0.3437,  0.1593, -0.0177,  0.3708, -0.1833,  0.0013,\n",
      "        -0.3046,  0.0940, -0.1468, -0.0996,  0.2428,  0.0054, -0.1256,  0.2749,\n",
      "        -0.0415, -0.2383, -0.0041, -0.2631,  0.1357,  0.3873,  0.0951,  0.1777,\n",
      "         0.4755,  0.2133, -0.1235, -0.1048, -0.0032,  0.1739, -0.1564, -0.0072],\n",
      "       requires_grad=True)\n",
      "16 blocks.1.norm1.weight Parameter containing:\n",
      "tensor([0.9112, 0.6938, 0.7860, 1.0521, 0.9971, 0.8783, 0.7581, 0.7770, 0.7644,\n",
      "        0.6902, 0.8510, 0.8240, 0.8070, 0.9832, 0.7471, 0.8810, 0.8082, 1.0408,\n",
      "        0.7364, 0.7625, 0.9815, 0.8114, 0.7349, 0.7424, 0.9656, 1.0546, 0.8445,\n",
      "        0.8689, 0.9333, 0.8689, 0.8158, 1.0010], requires_grad=True)\n",
      "17 blocks.1.norm1.bias Parameter containing:\n",
      "tensor([ 0.1644,  0.1836, -0.0890, -0.0022,  0.0744, -0.2773, -0.0216, -0.0289,\n",
      "         0.0948, -0.0813, -0.0310,  0.0393, -0.2500, -0.0646,  0.0411, -0.0578,\n",
      "         0.0342,  0.1180,  0.0768,  0.1103, -0.0542,  0.0811, -0.0231, -0.0205,\n",
      "        -0.1670,  0.0191, -0.0831,  0.1088,  0.1952, -0.0719,  0.0814,  0.0463],\n",
      "       requires_grad=True)\n",
      "18 blocks.1.attn.qkv.weight Parameter containing:\n",
      "tensor([[ 4.8761e-02,  3.0079e-01, -1.2890e-01,  ..., -1.0424e-01,\n",
      "         -7.0701e-02, -2.0378e-01],\n",
      "        [-3.8205e-02,  2.8075e-01, -3.3156e-03,  ...,  9.4047e-02,\n",
      "          2.4680e-01,  5.9065e-02],\n",
      "        [-2.4429e-02, -1.8964e-01, -6.4814e-02,  ...,  2.8698e-01,\n",
      "          9.5497e-02, -2.5816e-02],\n",
      "        ...,\n",
      "        [-1.2362e-01,  1.5709e-01, -3.5374e-04,  ...,  1.1908e-01,\n",
      "          4.2620e-02, -1.1073e-01],\n",
      "        [ 9.4676e-02, -1.8427e-01,  2.2650e-01,  ..., -7.3616e-02,\n",
      "          1.4642e-01, -5.2613e-01],\n",
      "        [-9.1634e-02, -2.5451e-01,  2.6381e-01,  ..., -1.7820e-01,\n",
      "         -2.7483e-02, -2.1962e-01]], requires_grad=True)\n",
      "19 blocks.1.attn.qkv.bias Parameter containing:\n",
      "tensor([ 0.1452, -0.0353, -0.6477, -0.4390, -0.1785,  0.3673,  0.1104, -0.0140,\n",
      "         0.4372,  0.0489, -0.2669, -0.0944,  0.4801, -0.0812,  0.1869,  0.3913,\n",
      "        -0.7943, -0.3567,  0.0642, -0.3622, -0.3535,  0.1739,  0.3527, -0.2275,\n",
      "         0.4397, -0.6229, -0.4256, -0.7175,  0.4243, -0.2060,  0.8022, -0.0307,\n",
      "        -0.0673, -0.0206,  0.0583,  0.1513, -0.1605,  0.0221,  0.0566,  0.1253,\n",
      "         0.1557, -0.0878,  0.0403,  0.1483,  0.0079, -0.0150,  0.1031,  0.0261,\n",
      "         0.1841,  0.1694,  0.0996, -0.0037, -0.0879, -0.1018, -0.0059,  0.1193,\n",
      "        -0.1581,  0.0415,  0.1874,  0.1094,  0.0088, -0.0155, -0.1819,  0.0317,\n",
      "         0.0321, -0.0562,  0.0678, -0.1416,  0.0740, -0.0521, -0.0287, -0.0122,\n",
      "         0.1291,  0.0674,  0.0376,  0.1099, -0.0369, -0.1252, -0.0759, -0.1215,\n",
      "        -0.0471, -0.1185, -0.1063, -0.0241, -0.2486, -0.1122, -0.0338, -0.1103,\n",
      "        -0.0108, -0.0040, -0.1253,  0.2394,  0.0840, -0.2998,  0.1722,  0.0217],\n",
      "       requires_grad=True)\n",
      "20 blocks.1.attn.proj.weight Parameter containing:\n",
      "tensor([[-0.2540,  0.1249,  0.0619,  ..., -0.5075,  0.0960,  0.1402],\n",
      "        [ 0.0899, -0.2236,  0.5126,  ...,  0.0639, -0.0147, -0.2931],\n",
      "        [ 0.2450,  0.2197,  0.0827,  ..., -0.0550,  0.2334, -0.0492],\n",
      "        ...,\n",
      "        [ 0.1810,  0.1080,  0.2359,  ...,  0.2409,  0.0275, -0.1698],\n",
      "        [ 0.1957,  0.2459,  0.0608,  ...,  0.1042,  0.1116, -0.0872],\n",
      "        [-0.0947,  0.2448,  0.3019,  ..., -0.4085,  0.2739,  0.0979]],\n",
      "       requires_grad=True)\n",
      "21 blocks.1.attn.proj.bias Parameter containing:\n",
      "tensor([-0.1562, -0.0342,  0.0499, -0.1659,  0.1131,  0.1968, -0.0976, -0.0093,\n",
      "         0.2283, -0.0981,  0.1171, -0.1401, -0.1224, -0.1163,  0.0593,  0.0687,\n",
      "         0.0077, -0.2305, -0.2588, -0.1308,  0.2126, -0.0765,  0.0548,  0.1545,\n",
      "         0.1829,  0.1529,  0.2687, -0.0998, -0.1412, -0.0457, -0.0947, -0.1234],\n",
      "       requires_grad=True)\n",
      "22 blocks.1.norm2.weight Parameter containing:\n",
      "tensor([0.9816, 0.9818, 1.0605, 1.0799, 0.8545, 0.9169, 0.9055, 0.7567, 0.9051,\n",
      "        1.0029, 0.9577, 0.8432, 1.0699, 0.7681, 1.1411, 0.7830, 0.6784, 0.8776,\n",
      "        0.8465, 1.0859, 0.8195, 1.0814, 0.9740, 0.8263, 0.9242, 1.0569, 1.0080,\n",
      "        1.0157, 0.7417, 0.9690, 1.1733, 0.8811], requires_grad=True)\n",
      "23 blocks.1.norm2.bias Parameter containing:\n",
      "tensor([-0.1479,  0.0927, -0.0743, -0.0253,  0.0259,  0.0425, -0.1663,  0.0427,\n",
      "         0.1462, -0.1406, -0.0130,  0.1049, -0.0385, -0.1241,  0.0727, -0.0307,\n",
      "        -0.3007,  0.1949,  0.2459,  0.0247,  0.0018, -0.0993,  0.0156, -0.0188,\n",
      "        -0.2008, -0.0444,  0.2008,  0.0942, -0.1479, -0.0125,  0.1896, -0.0470],\n",
      "       requires_grad=True)\n",
      "24 blocks.1.mlp.fc1.weight Parameter containing:\n",
      "tensor([[ 2.2566e-01, -2.2902e-01,  2.8224e-01,  2.9445e-01,  1.0976e-01,\n",
      "          1.3507e-01, -2.3499e-01, -2.4926e-02,  2.1557e-01, -2.2420e-01,\n",
      "          6.0556e-02,  4.1219e-02, -1.6752e-02,  1.9373e-01, -3.1812e-01,\n",
      "         -2.1246e-01,  4.0499e-02,  1.2406e-01, -1.0525e-01,  4.5609e-01,\n",
      "         -1.0919e-01, -7.1773e-02,  9.7036e-03, -1.4874e-01,  3.5059e-02,\n",
      "          4.0028e-01,  2.2285e-01, -4.2473e-02,  1.2930e-01, -2.4989e-02,\n",
      "          4.4369e-02,  1.8071e-03],\n",
      "        [ 1.3356e-01, -2.2616e-01,  1.2193e-01,  1.1965e-02,  2.2229e-02,\n",
      "         -3.6072e-02, -1.8553e-01,  2.4601e-01,  2.6349e-01,  1.8461e-01,\n",
      "          1.6068e-02, -3.4483e-02, -1.2692e-01,  9.5002e-03,  1.8217e-01,\n",
      "         -1.8928e-01,  1.9069e-01, -3.1979e-02, -1.2976e-01,  4.1175e-01,\n",
      "          9.5183e-02, -2.1563e-01, -5.2720e-02,  4.3049e-02,  2.7102e-04,\n",
      "         -1.2867e-01,  1.3899e-01,  1.4297e-01, -1.8540e-01, -1.1036e-01,\n",
      "         -2.0055e-01, -8.2201e-03],\n",
      "        [ 1.6484e-01, -2.9195e-01,  2.7029e-01,  2.4533e-01, -1.3253e-01,\n",
      "          3.3621e-01,  3.0846e-01,  5.4735e-02, -9.3229e-02,  1.7794e-01,\n",
      "         -1.8205e-01,  5.5004e-02,  2.7550e-01, -5.0777e-02, -2.6523e-01,\n",
      "         -2.8972e-03, -2.0438e-02, -1.1821e-01, -6.4798e-03, -1.5403e-01,\n",
      "          5.5594e-03,  5.4912e-01, -8.2957e-02, -2.6884e-02,  1.6981e-01,\n",
      "         -1.8962e-01, -6.3672e-02, -1.0625e-01,  1.6449e-01, -5.4527e-02,\n",
      "         -4.2736e-01, -2.1654e-01],\n",
      "        [-1.7737e-01, -5.5917e-02,  7.7815e-03, -1.0037e-01,  2.2737e-02,\n",
      "          3.5324e-02, -7.4830e-02, -1.9300e-02, -2.1853e-01,  4.2412e-02,\n",
      "         -4.1423e-02, -6.3001e-02,  2.7539e-01,  1.3024e-01,  1.9081e-01,\n",
      "          8.1449e-02,  9.3192e-02,  3.4574e-02, -3.4903e-01,  2.9625e-01,\n",
      "         -2.2483e-01, -1.4101e-01,  2.3745e-01,  1.9790e-01,  3.0060e-02,\n",
      "         -6.4889e-02, -3.8313e-01, -2.2191e-02,  1.0916e-01,  1.1890e-01,\n",
      "          2.1495e-01, -2.0345e-01],\n",
      "        [-1.8164e-01,  8.7531e-02, -2.3689e-01,  6.2997e-02,  1.8212e-01,\n",
      "          2.8944e-02,  1.4994e-01, -7.7467e-02, -1.0541e-01, -1.6743e-01,\n",
      "          2.9613e-01, -2.6613e-01, -4.8716e-02,  3.2512e-02,  1.6229e-01,\n",
      "          1.4844e-01,  1.2464e-01, -1.5991e-01,  2.4722e-01, -3.1665e-01,\n",
      "         -1.5782e-01, -2.4848e-01,  2.1935e-01, -1.1068e-01,  7.0942e-02,\n",
      "          4.0307e-01,  6.7367e-02, -1.4201e-01, -5.0786e-02,  2.9555e-03,\n",
      "          1.5380e-01,  2.6105e-01],\n",
      "        [ 2.0989e-01,  2.3283e-01,  7.1698e-02, -1.6162e-01, -2.6626e-01,\n",
      "         -4.2702e-02,  2.3409e-01, -6.1769e-02, -1.2087e-01,  1.4493e-01,\n",
      "         -2.5735e-04,  1.9666e-01,  4.0045e-02,  1.4155e-02, -2.4210e-01,\n",
      "          1.9537e-01, -4.2582e-02,  1.0674e-01,  1.7938e-01, -1.3896e-01,\n",
      "          5.6009e-02,  1.4689e-01, -1.2440e-01, -1.6934e-01, -9.1731e-02,\n",
      "         -1.0408e-01, -2.9835e-01, -7.8341e-03, -4.5339e-03, -2.4665e-01,\n",
      "          1.6163e-01,  1.7626e-01],\n",
      "        [-5.6575e-02,  1.6724e-01, -2.6568e-01, -9.8187e-02,  6.1935e-02,\n",
      "         -1.5449e-01, -5.1369e-02,  4.1909e-02,  2.1855e-01,  9.3316e-02,\n",
      "         -8.9215e-02,  2.4640e-02, -2.0053e-01, -2.5990e-01,  3.4395e-01,\n",
      "         -7.7665e-02, -7.3709e-02, -1.8349e-02, -2.5613e-02, -6.2081e-02,\n",
      "          3.5508e-01, -1.1128e-01, -1.7892e-01,  2.8313e-01,  1.3147e-01,\n",
      "         -1.1647e-02,  5.6471e-02,  2.0249e-01, -3.4413e-02, -4.2123e-01,\n",
      "         -2.6091e-02,  5.5524e-02],\n",
      "        [ 7.1052e-02, -7.3373e-02, -4.6525e-02,  1.7301e-01,  4.1358e-01,\n",
      "         -1.1707e-01,  8.5061e-02, -2.7710e-02,  9.2555e-02, -9.7109e-02,\n",
      "         -1.8753e-01, -2.8414e-01, -9.1652e-02,  1.3468e-01,  3.3949e-01,\n",
      "          7.6021e-03,  1.3864e-01, -3.8602e-01,  5.2392e-02, -2.2653e-02,\n",
      "          1.4822e-01,  9.8596e-02, -2.0905e-01, -1.5703e-01,  4.5825e-01,\n",
      "          7.8166e-03, -5.7626e-02, -2.6357e-01,  3.3220e-01, -3.6978e-01,\n",
      "         -9.5335e-02,  1.0533e-01],\n",
      "        [ 6.8326e-02,  2.3268e-01, -2.9751e-01,  2.5613e-01, -9.9048e-02,\n",
      "         -1.3068e-01,  3.0710e-01,  1.3074e-02,  1.5578e-02, -2.5078e-01,\n",
      "         -2.7411e-01, -1.2029e-01, -1.6170e-01, -8.2960e-02,  8.8240e-02,\n",
      "          3.0550e-01, -5.1459e-04, -6.3984e-02,  1.0870e-01, -9.8040e-02,\n",
      "         -1.9614e-02,  1.2954e-01,  5.9805e-02, -1.0561e-01, -7.2377e-02,\n",
      "          1.2135e-01, -4.5175e-02,  2.6387e-01,  6.5816e-02, -4.2864e-02,\n",
      "          7.8550e-03,  2.0784e-01],\n",
      "        [ 2.7390e-01, -9.6255e-02, -8.2654e-02,  7.4978e-02, -8.6015e-02,\n",
      "         -3.6323e-01,  7.6572e-02, -2.1919e-02,  4.2197e-02,  3.0623e-01,\n",
      "         -5.5411e-02,  1.7765e-01, -2.0089e-01, -1.1879e-01,  2.3022e-01,\n",
      "          2.5888e-02,  3.3538e-01, -5.0464e-02, -1.2975e-01,  4.7875e-02,\n",
      "         -1.1411e-01,  9.7843e-02, -5.4572e-02,  1.7879e-01,  1.4717e-02,\n",
      "         -1.7557e-01, -3.2579e-01, -2.2282e-01,  1.1385e-01, -2.1433e-01,\n",
      "         -2.7394e-01, -7.4185e-02],\n",
      "        [ 3.2455e-01,  5.9115e-02,  2.1182e-02,  3.3027e-01, -1.5147e-01,\n",
      "          9.7979e-02,  2.0487e-01, -3.0217e-01, -4.2254e-02, -1.5344e-01,\n",
      "          1.6235e-01, -6.0145e-03, -6.2884e-02,  2.8787e-01, -2.0924e-01,\n",
      "         -7.8431e-02,  8.1567e-02,  4.5928e-02,  7.1497e-03,  1.9928e-01,\n",
      "         -2.5353e-02, -5.1211e-02, -8.3738e-02, -1.1998e-01, -2.2855e-01,\n",
      "          2.0016e-02,  2.9864e-03,  2.0944e-01,  1.2315e-01,  1.4969e-02,\n",
      "         -3.6800e-01, -1.7868e-01],\n",
      "        [ 1.0186e-01,  6.6930e-02, -2.3996e-01, -1.5014e-01, -6.6477e-02,\n",
      "         -6.1186e-02, -2.9891e-02,  1.0569e-01, -3.0555e-01,  4.7174e-03,\n",
      "         -1.4867e-01,  1.9382e-01,  2.5695e-01,  1.1381e-02, -8.1832e-03,\n",
      "         -2.6682e-02,  7.8677e-02,  1.6941e-01, -2.0090e-01,  1.9675e-01,\n",
      "         -2.0827e-02,  2.4313e-02,  2.6040e-01, -4.3358e-03, -7.0514e-02,\n",
      "         -2.6012e-01, -1.1276e-01,  3.6606e-01,  8.9805e-02,  2.2895e-02,\n",
      "         -6.7795e-02, -1.7993e-01]], requires_grad=True)\n",
      "25 blocks.1.mlp.fc1.bias Parameter containing:\n",
      "tensor([-0.1865,  0.0861,  0.1088, -0.0244, -0.1403, -0.1099, -0.0995, -0.3531,\n",
      "        -0.0461, -0.2804, -0.1889, -0.1640], requires_grad=True)\n",
      "26 blocks.1.mlp.fc2.weight Parameter containing:\n",
      "tensor([[-1.3142e-01, -1.1695e-01,  5.1709e-02,  1.5346e-01, -1.8862e-01,\n",
      "          1.9450e-01,  4.3834e-01, -8.7157e-02,  4.6269e-01, -2.2868e-01,\n",
      "         -1.2502e-02, -1.9324e-01],\n",
      "        [-7.3904e-02, -1.0147e-01,  1.9686e-01,  2.1895e-01, -2.5819e-01,\n",
      "          2.2958e-01, -4.0280e-01,  4.0248e-01,  6.5181e-02,  3.6892e-01,\n",
      "         -4.6117e-01, -3.4451e-01],\n",
      "        [ 1.4568e-01,  2.1724e-01, -2.0369e-01, -4.8949e-02, -1.3568e-01,\n",
      "         -1.2684e-01,  4.6566e-02, -1.5623e-01, -1.3002e-01, -1.5527e-01,\n",
      "          4.7673e-01, -3.1267e-01],\n",
      "        [-1.5607e-01, -6.7670e-02,  3.8228e-01, -2.5736e-01,  2.9365e-01,\n",
      "         -3.9997e-01,  6.5632e-01,  2.4679e-01, -2.1838e-01, -3.5325e-03,\n",
      "          3.7714e-01, -6.0346e-01],\n",
      "        [-1.5258e-01, -4.4044e-01,  3.1951e-01, -1.4120e-01,  1.0769e-01,\n",
      "          2.6817e-02,  8.3597e-02, -4.1405e-01, -3.2460e-02, -1.4864e-02,\n",
      "          4.7437e-03, -1.4062e-01],\n",
      "        [-2.5880e-01, -3.0558e-01, -3.0314e-01, -9.8209e-02, -3.1252e-01,\n",
      "         -3.9932e-02,  1.2867e-01,  2.2379e-01, -1.0807e-01,  9.3175e-02,\n",
      "          1.1182e-01,  3.5349e-01],\n",
      "        [ 1.7205e-01, -1.4350e-01, -2.2566e-01,  8.3888e-02,  4.9333e-02,\n",
      "          1.2376e-01,  4.5486e-01,  3.8847e-01, -2.8081e-01, -6.1651e-02,\n",
      "          1.9131e-02,  3.6003e-02],\n",
      "        [-6.0651e-02, -3.2295e-02,  1.4245e-01,  4.0784e-02, -1.7334e-01,\n",
      "         -2.8189e-01, -8.9176e-02, -2.8122e-01,  8.7167e-02,  1.7442e-01,\n",
      "         -1.3944e-01,  3.5255e-01],\n",
      "        [-2.4050e-01,  1.3849e-01, -1.4009e-01,  3.7889e-01, -1.8774e-01,\n",
      "         -3.7652e-01, -6.2205e-01, -5.6444e-02,  4.8939e-01,  1.2016e-02,\n",
      "          3.2400e-03,  9.9468e-02],\n",
      "        [ 3.9267e-01,  5.2327e-02, -4.3281e-01, -1.7589e-01,  8.8616e-02,\n",
      "          3.7568e-01,  2.2440e-01, -5.0706e-02, -2.1504e-01, -2.2227e-01,\n",
      "         -1.8172e-02,  2.0165e-01],\n",
      "        [ 3.8430e-01, -1.4926e-01,  1.6793e-01,  1.4124e-01, -1.9044e-01,\n",
      "          2.9783e-01,  4.6956e-02,  2.2608e-01, -8.0743e-02, -2.2667e-01,\n",
      "         -5.9908e-01, -2.0156e-01],\n",
      "        [-2.0307e-02, -3.4073e-01, -3.4709e-01, -3.4039e-01, -2.3891e-01,\n",
      "         -6.1369e-03, -1.0339e-01,  2.7270e-01,  4.4782e-01, -2.0194e-01,\n",
      "          8.1620e-02, -3.2716e-01],\n",
      "        [-3.3317e-01,  3.8231e-01,  2.2507e-01,  1.2882e-02, -1.1148e-01,\n",
      "         -1.5036e-01, -2.7317e-01,  4.0211e-01,  1.6809e-02, -1.7810e-01,\n",
      "          5.2719e-02,  2.5402e-01],\n",
      "        [-3.6658e-01, -1.6856e-01, -1.5958e-01,  1.5182e-01, -2.6667e-01,\n",
      "         -2.2934e-01, -4.4534e-02, -4.7903e-01,  3.0752e-01,  4.6659e-01,\n",
      "         -2.0733e-01, -1.5627e-01],\n",
      "        [-1.3580e-01, -5.0379e-02,  9.7451e-02, -1.6881e-01,  2.9657e-01,\n",
      "          3.5185e-01,  3.7581e-01,  4.6678e-01, -8.0608e-01, -2.9279e-02,\n",
      "          8.1039e-03,  1.0266e-01],\n",
      "        [ 1.1878e-03, -1.8729e-01,  1.8849e-01,  6.7173e-02, -1.1166e-01,\n",
      "          4.2889e-05,  3.4180e-01,  4.5976e-01, -1.9287e-01,  1.0604e-01,\n",
      "          4.2516e-01,  1.3997e-01],\n",
      "        [ 3.0889e-02,  7.8755e-02,  5.3533e-02,  2.8694e-01, -5.8572e-02,\n",
      "          1.5098e-02, -7.7496e-03, -2.3674e-02,  1.2645e-01,  1.5503e-01,\n",
      "         -2.0907e-01,  2.0854e-01],\n",
      "        [-9.0568e-03,  2.5294e-02, -2.0981e-01, -2.8108e-01,  7.9200e-03,\n",
      "         -2.7569e-02,  2.8452e-01,  8.1719e-02, -6.3901e-01,  6.8577e-03,\n",
      "          5.8582e-01, -7.6743e-02],\n",
      "        [ 3.7345e-01, -5.0322e-02, -5.8181e-01,  6.1748e-02,  1.1782e-01,\n",
      "          2.3698e-01, -3.6215e-01, -2.9769e-01,  2.2406e-01,  1.0451e-01,\n",
      "         -3.4369e-01,  1.6905e-02],\n",
      "        [-2.1833e-01,  1.7223e-01, -2.7048e-01, -4.0754e-02, -9.9926e-02,\n",
      "          2.5804e-01, -3.9119e-01,  2.8857e-02,  4.3474e-02,  4.1333e-01,\n",
      "          2.0057e-01, -1.4607e-01],\n",
      "        [ 1.4014e-01,  2.0206e-01,  3.5263e-01,  1.2115e-01, -3.0289e-02,\n",
      "         -8.3516e-05, -4.7475e-01,  3.9002e-01,  2.4172e-01,  2.0233e-01,\n",
      "         -5.1078e-01,  1.2619e-01],\n",
      "        [ 1.5556e-01,  1.6455e-01,  4.9661e-01,  1.4500e-01, -5.3061e-02,\n",
      "          2.9797e-02, -3.0420e-02,  3.4435e-01, -1.1084e-01,  2.6901e-01,\n",
      "         -3.6781e-01,  3.5197e-01],\n",
      "        [ 3.9364e-02, -6.2194e-02, -1.9824e-01, -1.7445e-01, -2.7341e-02,\n",
      "         -5.6427e-02,  1.8801e-01,  3.4999e-01, -5.1215e-01,  1.5921e-01,\n",
      "          3.5587e-01, -4.8779e-01],\n",
      "        [-3.8018e-02, -9.0440e-02,  2.4225e-01, -2.2135e-01,  4.4653e-01,\n",
      "          1.6840e-01, -1.3762e-01,  3.6363e-01, -5.8366e-01, -9.7136e-02,\n",
      "         -2.5251e-02, -2.2117e-02],\n",
      "        [ 3.7399e-01,  2.2309e-01,  1.2665e-01,  2.2229e-01,  3.2643e-01,\n",
      "         -5.1543e-02,  1.8413e-01, -5.7484e-01, -1.9625e-01,  3.7326e-02,\n",
      "          1.5916e-01,  1.3493e-01],\n",
      "        [-2.8578e-01,  4.1970e-01,  2.3841e-01,  4.1362e-01,  6.4590e-01,\n",
      "         -1.0597e-01, -5.0158e-01, -5.1644e-01,  5.1754e-01, -1.4164e-01,\n",
      "          2.5267e-01,  1.5671e-01],\n",
      "        [-1.3084e-01, -1.6357e-01, -3.5514e-01, -1.5438e-01, -1.1502e-02,\n",
      "         -1.2605e-01,  6.8672e-02, -3.9171e-01,  3.8789e-05, -7.2843e-01,\n",
      "          3.5853e-01,  1.6645e-01],\n",
      "        [-5.1217e-01,  2.6813e-01,  1.8350e-01, -3.8350e-01, -8.4952e-02,\n",
      "         -2.5671e-02, -6.9348e-02, -9.8626e-02, -1.2311e-02,  1.2347e-01,\n",
      "         -3.1648e-01,  5.6626e-01],\n",
      "        [ 5.3122e-02, -2.3833e-01, -2.4382e-01, -2.1759e-01,  5.3597e-02,\n",
      "         -3.0239e-01, -4.2761e-02, -1.2615e-01,  4.6728e-01,  1.5351e-01,\n",
      "         -4.6001e-01,  9.6370e-02],\n",
      "        [ 5.8824e-01, -9.5586e-02,  1.7496e-01,  3.7530e-02,  1.1677e-01,\n",
      "          2.9617e-01,  1.8855e-01,  9.4843e-04, -3.5803e-01,  4.9280e-01,\n",
      "          1.0813e-01, -4.4745e-01],\n",
      "        [ 1.0373e-01,  2.7608e-01,  1.6789e-01,  4.3458e-01, -1.7532e-01,\n",
      "          1.9619e-02, -1.2935e-01, -4.1903e-02,  5.9384e-02,  3.1299e-01,\n",
      "         -6.8205e-02, -3.7107e-01],\n",
      "        [ 3.4157e-01,  1.8833e-02,  2.0147e-01,  1.5313e-01, -1.7792e-01,\n",
      "         -1.7459e-01,  1.8677e-01, -2.0571e-01,  3.1410e-01, -2.9634e-01,\n",
      "         -8.3500e-02,  6.8835e-02]], requires_grad=True)\n",
      "27 blocks.1.mlp.fc2.bias Parameter containing:\n",
      "tensor([ 0.2923,  0.3282, -0.3172,  0.2755, -0.1191, -0.0761,  0.2122, -0.3247,\n",
      "        -0.3219, -0.2904,  0.1832,  0.0571,  0.0512,  0.1335,  0.1832, -0.0613,\n",
      "        -0.1686, -0.4225, -0.1915,  0.0985,  0.2355,  0.0797, -0.1166,  0.1388,\n",
      "         0.0844,  0.5802,  0.1801, -0.1515,  0.0328, -0.0606, -0.0669, -0.2719],\n",
      "       requires_grad=True)\n",
      "28 norm.weight Parameter containing:\n",
      "tensor([1.7747, 1.4917, 1.6197, 1.5779, 1.5104, 1.4884, 1.5362, 1.3611, 1.4187,\n",
      "        1.7078, 1.6985, 1.6390, 1.4516, 1.6100, 1.4507, 1.4646, 1.5929, 1.5293,\n",
      "        1.3137, 1.5417, 1.4824, 1.4481, 1.5802, 1.3600, 1.5619, 1.3735, 1.5717,\n",
      "        1.5012, 1.4898, 1.3854, 1.7713, 1.2873], requires_grad=True)\n",
      "29 norm.bias Parameter containing:\n",
      "tensor([ 0.0203,  0.0383, -0.0213, -0.2340,  0.0333,  0.0502, -0.0243,  0.0808,\n",
      "        -0.0048,  0.2621,  0.1291,  0.0696, -0.0877, -0.0033,  0.0926, -0.1714,\n",
      "         0.0946,  0.0818,  0.2862,  0.0676, -0.0495,  0.0817, -0.0908,  0.0032,\n",
      "        -0.0576, -0.2079,  0.0078,  0.1514,  0.0609, -0.0881, -0.0688, -0.0171],\n",
      "       requires_grad=True)\n",
      "30 head.weight Parameter containing:\n",
      "tensor([[-7.0662e-02,  1.3499e-01, -3.8009e-01,  6.0584e-01,  4.1917e-01,\n",
      "         -3.7075e-01,  2.0450e-01, -4.0412e-01,  6.2776e-02, -4.6475e-01,\n",
      "         -5.9376e-01, -2.4132e-01, -4.2393e-01,  1.8389e-01,  1.8460e-01,\n",
      "          2.1956e-01, -3.1886e-01, -3.3674e-01,  8.8356e-02, -4.2352e-01,\n",
      "         -4.0939e-02, -1.0542e-01,  1.8793e-01, -7.2534e-02,  1.6244e-01,\n",
      "         -1.2656e-01,  3.3465e-01,  8.5337e-02,  5.2124e-01, -3.7563e-01,\n",
      "         -4.5943e-01,  1.7528e-01],\n",
      "        [ 3.0352e-02, -5.3761e-01,  5.1218e-01,  5.0710e-01, -1.9978e-01,\n",
      "          1.8169e-01,  2.8051e-01, -2.8327e-04,  1.3403e-01,  3.0515e-01,\n",
      "         -1.6733e-01, -1.4994e-01, -2.9695e-01, -4.3653e-02, -2.0136e-01,\n",
      "         -3.6033e-01,  3.7734e-01,  7.5984e-01, -3.7332e-01,  2.5667e-01,\n",
      "         -2.6232e-01, -1.7522e-01, -3.5150e-01, -4.4539e-02,  3.4139e-02,\n",
      "          2.3827e-01,  3.2483e-01, -4.8200e-01, -3.3107e-01,  6.6220e-04,\n",
      "         -1.3452e-01, -4.9982e-03],\n",
      "        [-1.8054e-01, -3.1714e-01,  4.3834e-02, -1.5373e-01,  4.0802e-01,\n",
      "          3.0738e-01, -1.2508e-01,  2.7700e-01,  4.3899e-01,  5.5846e-01,\n",
      "          2.1806e-01, -9.6559e-02, -2.9435e-01,  8.5169e-02,  3.8948e-01,\n",
      "         -3.4951e-01,  2.4702e-01, -1.7520e-01, -2.9415e-03, -4.1315e-02,\n",
      "          2.3549e-01,  2.4263e-01, -5.3219e-01,  4.3015e-01,  3.5472e-01,\n",
      "         -1.2378e-01,  3.5077e-01, -2.0200e-01,  3.4359e-01, -6.6013e-01,\n",
      "         -5.8778e-01, -1.6139e-01],\n",
      "        [-2.9198e-01, -2.7329e-01,  1.5756e-01, -2.4867e-01,  8.9417e-02,\n",
      "          2.3414e-01, -2.4737e-01,  2.3148e-01,  2.1705e-01, -3.7169e-01,\n",
      "          2.6820e-01,  4.5165e-01,  4.8011e-01, -2.7147e-01,  3.6934e-01,\n",
      "         -4.0749e-01, -2.0289e-01, -5.9938e-02, -2.7835e-01, -1.2312e-01,\n",
      "          2.2346e-01, -4.6082e-01,  3.0568e-01,  3.6012e-01, -3.5758e-01,\n",
      "          1.2761e-01,  2.2901e-01, -2.3909e-01, -2.1400e-01,  3.9785e-02,\n",
      "          3.6608e-01, -2.2432e-01],\n",
      "        [ 3.1808e-01,  1.6361e-01, -5.3151e-01, -5.7490e-02, -3.4209e-01,\n",
      "         -7.1168e-02,  5.5124e-01, -3.6624e-01, -2.8539e-01,  2.5833e-01,\n",
      "          6.3101e-02,  1.8964e-01,  3.0680e-01,  2.6596e-01, -2.7185e-01,\n",
      "          3.1318e-01,  4.3693e-01,  3.1748e-01, -3.4351e-02, -5.3779e-02,\n",
      "         -4.4899e-01,  1.4710e-01, -7.2955e-02, -2.7403e-01, -3.3528e-01,\n",
      "         -3.3355e-01, -3.8520e-01,  3.3776e-01, -6.9318e-02,  1.5690e-01,\n",
      "         -5.4700e-01, -4.0055e-01],\n",
      "        [-3.8485e-01,  3.2392e-01,  2.1606e-01, -3.4132e-01, -5.2945e-02,\n",
      "         -5.6807e-01, -2.9394e-01,  2.3735e-01, -1.6277e-01, -3.1090e-01,\n",
      "         -4.7150e-01, -3.2620e-01,  8.1708e-02, -4.2242e-01, -3.4786e-03,\n",
      "          1.9497e-01, -3.2167e-01, -1.3660e-01, -8.5525e-02,  2.2041e-01,\n",
      "          3.6731e-01, -4.0298e-01,  1.4728e-01,  2.2276e-01,  1.1586e-01,\n",
      "          1.2572e-01, -5.0553e-02,  5.2880e-01, -3.1495e-01,  1.2935e-01,\n",
      "          4.0558e-01,  3.3001e-01],\n",
      "        [-2.7471e-01,  3.1913e-01,  2.7833e-01,  2.6196e-01,  3.4191e-01,\n",
      "         -5.6097e-01,  3.9589e-01, -2.6129e-02,  2.1695e-01,  9.3651e-02,\n",
      "         -6.9874e-01, -3.6346e-01, -3.9845e-01,  5.5253e-01,  1.0878e-01,\n",
      "          2.4859e-01,  3.0128e-01, -1.4754e-01, -2.5752e-01,  6.2928e-01,\n",
      "         -1.2901e-02, -1.0364e-01,  2.1258e-01,  1.9568e-01,  3.0191e-01,\n",
      "         -4.2708e-01, -5.5330e-01, -1.3913e-01,  5.6179e-01,  1.1965e-01,\n",
      "          1.4981e-02, -1.4524e-01],\n",
      "        [ 6.8941e-01, -2.3531e-01, -1.9712e-01, -2.2538e-02, -2.9447e-01,\n",
      "          2.4514e-01, -2.2437e-02,  3.3288e-01,  4.3496e-01, -4.7282e-02,\n",
      "          3.1498e-01,  4.1810e-01, -6.2002e-03, -1.7665e-01, -5.3883e-01,\n",
      "         -3.0075e-01,  5.1350e-01, -1.6667e-01,  3.8576e-01, -3.5322e-01,\n",
      "          2.3290e-01,  3.5336e-01, -5.1978e-01, -3.4039e-01, -4.4580e-01,\n",
      "          2.7498e-01,  2.7252e-01, -2.1813e-01, -8.3805e-02, -4.2938e-01,\n",
      "          1.6631e-01,  2.2453e-01],\n",
      "        [-2.0935e-01,  7.5188e-02, -1.6132e-02, -2.5073e-01,  3.9894e-01,\n",
      "          1.8144e-01, -3.3273e-01, -2.6652e-01, -1.4211e-01,  3.2640e-01,\n",
      "          2.1024e-01, -3.3081e-01,  2.3006e-01,  3.0565e-01, -3.5059e-01,\n",
      "          3.4438e-02, -2.6455e-01, -3.5111e-01,  3.1036e-01,  6.9776e-02,\n",
      "         -3.1493e-01, -1.5650e-01,  7.8121e-02, -2.2023e-01,  3.2235e-01,\n",
      "          5.1366e-02,  1.8662e-01, -2.7377e-01, -1.4956e-01,  1.8010e-01,\n",
      "          3.3583e-02, -1.8554e-01],\n",
      "        [ 3.4102e-01,  2.5776e-01, -1.2326e-01, -1.3406e-01, -2.0269e-01,\n",
      "          8.1846e-02,  2.9824e-01, -3.0876e-01, -3.2759e-01,  1.4421e-01,\n",
      "          2.4605e-01,  1.5572e-01,  8.5378e-02, -3.1285e-01,  1.3058e-01,\n",
      "          1.4342e-01, -2.2370e-01, -6.7050e-02,  3.7010e-01, -3.9500e-01,\n",
      "          1.1542e-02,  2.5621e-01,  2.8539e-01, -1.1901e-01, -4.4891e-01,\n",
      "         -2.8812e-01, -2.7159e-01, -1.0295e-01, -2.0197e-01,  3.1497e-01,\n",
      "          3.1011e-01,  3.1235e-01]], requires_grad=True)\n",
      "31 head.bias Parameter containing:\n",
      "tensor([-0.1678, -0.0190,  0.0916,  0.0227, -0.0017,  0.0028, -0.0895, -0.0904,\n",
      "         0.1494,  0.2000], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for i, (name, param) in enumerate(MNIST_ViT.named_parameters()):\n",
    "    print(i, name,param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 cls_token Parameter containing:\n",
      "tensor([[[-0.0122, -0.1364, -0.0094, -0.0141,  0.0223,  0.0042,  0.0245,\n",
      "          -0.0475, -0.0308, -0.0016,  0.0057,  0.0205,  0.1222,  0.0767,\n",
      "          -0.0336,  0.0040, -0.0123, -0.0162, -0.4628,  0.0262,  0.0148,\n",
      "          -0.0054, -0.1923,  0.0093,  0.0606, -0.0081,  0.0104, -0.0111,\n",
      "           0.0501,  0.1046, -0.0188,  0.0386]]], requires_grad=True)\n",
      "1 pos_embed Parameter containing:\n",
      "tensor([[[-0.0122, -0.1364, -0.0094,  ...,  0.1046, -0.0188,  0.0386],\n",
      "         [-0.1002,  0.2293,  0.1266,  ..., -0.2201,  0.0879,  0.2167],\n",
      "         [ 0.1388,  0.2504,  0.1720,  ..., -0.0359,  0.2639,  0.1905],\n",
      "         ...,\n",
      "         [-0.3200,  0.4005,  0.3438,  ...,  0.2797, -0.2134,  0.1789],\n",
      "         [ 0.1282,  0.2640,  0.3549,  ...,  0.2232,  0.1646,  0.0010],\n",
      "         [-0.6103,  0.2312, -0.1634,  ...,  0.1081, -0.1291,  0.5354]]],\n",
      "       requires_grad=True)\n",
      "2 patch_embed.proj.weight Parameter containing:\n",
      "tensor([[[[ 9.8508e-02, -1.6454e-01, -1.0587e-01,  5.7849e-02],\n",
      "          [ 5.7368e-03,  1.1244e-01,  9.3835e-02,  2.8764e-01],\n",
      "          [-1.8462e-01,  8.6324e-02, -2.8885e-02,  2.9850e-01],\n",
      "          [-2.1216e-01, -2.0213e-01, -3.3993e-01, -3.6425e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.8553e-02,  3.1582e-01,  1.2331e-01,  4.3918e-01],\n",
      "          [-3.1045e-01, -3.5102e-02,  1.2066e-02,  5.4815e-02],\n",
      "          [-6.5735e-02,  2.9189e-02,  5.1786e-02,  9.8952e-03],\n",
      "          [ 4.7078e-02,  1.9497e-01,  1.2696e-01,  1.2059e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.6702e-01, -1.4295e-02, -1.8229e-01,  2.2014e-02],\n",
      "          [-1.6708e-01,  5.5129e-02, -1.7927e-01,  1.8484e-01],\n",
      "          [-2.5268e-02,  1.4035e-02, -8.4881e-02,  4.3245e-01],\n",
      "          [ 4.6601e-02, -8.0072e-02, -5.0797e-02,  4.1464e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.8921e-01,  2.4021e-01,  2.2549e-01,  1.5910e-01],\n",
      "          [-6.3668e-02,  3.1490e-03, -1.3112e-01, -3.2002e-01],\n",
      "          [-2.1168e-02, -3.2535e-01, -2.1249e-01, -2.5986e-01],\n",
      "          [-5.8033e-02,  1.8220e-01,  4.1205e-01, -1.0072e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.4969e-02,  1.6930e-01, -1.5076e-02,  1.9490e-01],\n",
      "          [ 8.3943e-02, -4.8572e-02, -2.6104e-01,  2.6281e-01],\n",
      "          [ 2.6818e-03, -8.3566e-02, -2.5162e-01,  3.8853e-01],\n",
      "          [-9.6465e-02, -1.5311e-01, -1.5500e-01,  5.5032e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.7340e-01, -5.2023e-03, -2.4676e-01,  1.3181e-01],\n",
      "          [-1.2168e-01,  8.8690e-02,  2.9479e-02,  2.7350e-01],\n",
      "          [-2.4811e-01,  7.8170e-02,  2.4861e-01, -3.2915e-02],\n",
      "          [ 3.9304e-02, -1.4136e-02, -1.2088e-01, -1.3018e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.4463e-01, -1.1520e-01, -8.5184e-02, -1.2912e-01],\n",
      "          [ 4.8133e-02,  5.2418e-02,  1.0743e-02, -4.6728e-02],\n",
      "          [ 1.4714e-01,  1.7788e-01,  3.4655e-01,  4.7897e-02],\n",
      "          [-1.2884e-01,  2.0417e-01,  1.9535e-01,  3.5501e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.9505e-01, -1.9855e-01, -3.3798e-01, -3.7044e-01],\n",
      "          [-3.6983e-03, -1.8147e-01, -1.1990e-01,  3.5492e-01],\n",
      "          [-4.6022e-01, -2.2440e-01,  1.7354e-01,  2.2778e-01],\n",
      "          [ 4.7912e-01,  4.4712e-01,  3.8919e-01,  3.4903e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.2519e-02, -9.3616e-02, -1.2925e-01, -2.1906e-01],\n",
      "          [ 2.0181e-01,  1.2521e-01, -1.7857e-01, -3.8602e-02],\n",
      "          [ 2.6158e-01,  3.3850e-02, -5.2311e-02,  1.3898e-01],\n",
      "          [-2.3160e-01, -1.5655e-01, -3.2001e-01,  1.2921e-01]]],\n",
      "\n",
      "\n",
      "        [[[-5.1126e-02, -8.1965e-02, -5.2810e-02,  2.0570e-01],\n",
      "          [ 1.1238e-02,  2.8274e-02,  2.7647e-02, -1.4767e-02],\n",
      "          [-3.5785e-02, -1.4478e-02,  6.4108e-02, -1.6523e-01],\n",
      "          [-1.2735e-01, -4.5090e-02,  1.5792e-01, -2.7239e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.3669e-01,  1.6919e-01,  6.9188e-02,  1.3500e-01],\n",
      "          [-7.2562e-02,  5.6483e-02,  2.3079e-01, -1.2732e-01],\n",
      "          [-1.9205e-01,  1.9884e-01,  2.6680e-01, -3.4308e-01],\n",
      "          [ 5.7785e-02,  1.8916e-01,  1.9773e-01,  3.0036e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.1935e-01,  7.3988e-02,  7.8323e-02,  2.7469e-02],\n",
      "          [ 1.2917e-01,  2.9511e-01,  4.2360e-01,  1.4568e-01],\n",
      "          [ 1.2802e-02, -8.8790e-02, -7.8041e-02,  2.1595e-02],\n",
      "          [-8.6665e-02, -6.9283e-02, -9.9945e-02,  1.6522e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.0837e-01,  1.8993e-01,  3.7995e-02,  1.2903e-01],\n",
      "          [-2.3812e-01, -1.1050e-01,  1.5619e-02,  1.1772e-01],\n",
      "          [-1.4358e-01,  9.3776e-02,  4.5960e-02,  1.6057e-01],\n",
      "          [ 2.1156e-01,  6.0525e-02, -5.9671e-02, -1.6941e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 3.8349e-02, -5.7763e-02, -1.1398e-01, -3.1797e-01],\n",
      "          [ 2.3968e-01,  9.0963e-03,  5.7536e-02, -3.4461e-02],\n",
      "          [ 1.4426e-01,  4.4976e-02,  4.4510e-02,  1.3026e-02],\n",
      "          [ 2.1435e-01, -7.3667e-02,  5.5423e-02, -1.7434e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.0311e-01, -1.5334e-01, -7.2286e-02, -8.5891e-02],\n",
      "          [-6.0427e-02,  9.0033e-03,  4.3549e-02,  3.6514e-02],\n",
      "          [ 1.3588e-01,  8.8195e-03, -5.2447e-02,  5.6142e-02],\n",
      "          [-3.8181e-01, -1.1855e-01, -2.1780e-01,  4.2125e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.7444e-01, -1.8422e-01, -2.8730e-01, -5.6898e-01],\n",
      "          [ 2.0151e-01, -7.1005e-02, -1.5941e-02, -3.4606e-01],\n",
      "          [-1.0972e-02, -1.3264e-01, -6.3037e-02, -2.3785e-01],\n",
      "          [ 3.3429e-01, -3.0666e-02,  1.4117e-01, -2.6470e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 9.4218e-02,  2.7864e-02, -9.4770e-02,  1.2451e-01],\n",
      "          [-5.5049e-02,  6.5233e-02, -2.6771e-01,  3.9007e-01],\n",
      "          [-3.0873e-01, -2.6711e-01, -4.3063e-01,  2.8447e-01],\n",
      "          [-5.9960e-01,  2.0703e-02, -2.2027e-01,  4.1495e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.3606e-02, -1.7572e-01, -8.9472e-03, -2.1892e-01],\n",
      "          [ 2.3239e-01,  1.5407e-01,  7.0519e-02, -4.8554e-02],\n",
      "          [ 5.4954e-03,  1.7057e-01,  1.8973e-01,  7.6907e-02],\n",
      "          [ 1.6758e-01,  6.3391e-02, -4.8491e-02,  1.0009e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.5844e-01, -1.7892e-01, -1.3343e-01, -1.2834e-01],\n",
      "          [ 1.6670e-01, -1.7056e-01, -8.8040e-02, -2.0386e-01],\n",
      "          [ 1.2753e-01, -3.1814e-01, -2.0180e-01, -1.8830e-01],\n",
      "          [ 1.5304e-01, -7.1549e-03, -1.0326e-01,  2.1620e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.3760e-01, -6.6828e-02,  8.3543e-02, -1.5592e-01],\n",
      "          [ 1.7243e-01, -1.4861e-01,  8.5817e-02, -2.2690e-01],\n",
      "          [ 1.6802e-01, -4.4844e-02, -1.3220e-01, -2.3911e-01],\n",
      "          [ 2.3258e-01,  1.2934e-01,  1.4171e-01,  3.9824e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.5733e-01,  2.0864e-01,  1.5330e-01,  4.8928e-02],\n",
      "          [-2.7295e-01,  5.5175e-02, -7.7545e-02, -9.9922e-02],\n",
      "          [-9.0327e-02, -8.1040e-02,  6.5454e-03, -4.7069e-02],\n",
      "          [-1.6896e-01,  6.3163e-02, -9.8137e-02,  3.4401e-02]]],\n",
      "\n",
      "\n",
      "        [[[-9.0480e-03, -2.5234e-02, -3.6739e-02,  1.4925e-01],\n",
      "          [-3.2313e-01, -2.4797e-01, -4.5005e-01, -2.9585e-01],\n",
      "          [ 7.0391e-02, -4.1590e-02, -1.4938e-01, -2.5660e-01],\n",
      "          [ 2.3439e-01,  1.0072e-02,  1.1774e-01,  5.2809e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.1381e-02, -1.1960e-02, -3.4939e-02, -1.6938e-01],\n",
      "          [-4.3448e-03,  1.0542e-01,  1.1818e-01, -3.8477e-02],\n",
      "          [ 6.8355e-02,  5.2448e-02, -1.6414e-01, -1.9519e-01],\n",
      "          [-1.4634e-01, -2.0461e-01, -4.0016e-01,  1.2440e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 6.0814e-02,  1.0819e-01,  1.7581e-01,  3.3928e-01],\n",
      "          [-1.3463e-01, -6.0941e-02, -7.6658e-02,  4.8418e-01],\n",
      "          [-2.9681e-02, -1.0244e-01, -1.7165e-01,  4.9518e-01],\n",
      "          [-2.6445e-01, -1.7119e-01, -2.5313e-01,  1.3256e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.3480e-01, -1.1863e-01,  1.0350e-01, -1.1969e-01],\n",
      "          [ 1.7646e-02,  2.8067e-02,  5.4899e-02,  8.1017e-03],\n",
      "          [ 7.5717e-02,  4.0198e-02,  2.6960e-01, -1.1236e-01],\n",
      "          [ 1.3544e-02, -5.6327e-02, -2.7678e-01, -4.1516e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.5575e-01, -2.4565e-02,  2.4260e-03, -2.5052e-01],\n",
      "          [-3.2385e-03,  1.1650e-02,  1.5548e-02, -1.4521e-03],\n",
      "          [-2.3827e-01, -2.7999e-02, -6.4678e-02, -2.5302e-01],\n",
      "          [-7.8783e-04,  6.4211e-02,  1.2739e-01,  1.4718e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.0271e-01, -1.0717e-01, -1.1436e-01,  2.4034e-01],\n",
      "          [ 2.4130e-02,  2.0796e-02, -1.6677e-01,  2.0191e-01],\n",
      "          [ 1.5908e-01,  2.0224e-01,  3.1105e-01,  2.6468e-01],\n",
      "          [-2.8374e-02, -1.5716e-01,  1.0709e-02, -3.3861e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.0713e-01,  3.2985e-01,  3.3700e-01,  3.4059e-01],\n",
      "          [ 3.3688e-01,  2.5634e-01,  2.9317e-02,  4.0933e-02],\n",
      "          [ 1.8216e-01, -8.8761e-02, -6.6401e-03, -2.0652e-02],\n",
      "          [-5.1194e-02, -2.2039e-01, -2.2058e-02, -5.3697e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0138e-02,  1.8167e-01,  1.7393e-01,  8.9308e-02],\n",
      "          [-1.4578e-01,  3.8979e-02, -1.4216e-01,  1.4805e-02],\n",
      "          [-1.3634e-01, -6.1156e-03,  4.4406e-02, -8.6780e-02],\n",
      "          [-5.7867e-02, -2.8947e-01, -2.9683e-01, -3.9659e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 8.7554e-02,  5.4145e-02,  2.7641e-01, -3.4538e-01],\n",
      "          [ 2.5708e-01,  9.2645e-02,  8.9001e-02,  1.3893e-01],\n",
      "          [ 2.6357e-01, -3.2158e-02, -8.2594e-02,  1.2370e-01],\n",
      "          [ 1.1900e-01,  8.3982e-04, -1.1012e-02,  1.6646e-01]]],\n",
      "\n",
      "\n",
      "        [[[-5.5483e-02, -2.0205e-02,  1.8436e-04,  6.8521e-02],\n",
      "          [-1.2130e-01, -1.6792e-01, -1.4022e-01, -4.3008e-02],\n",
      "          [-1.5084e-01, -7.0904e-02,  1.5942e-01, -6.9582e-02],\n",
      "          [ 5.0601e-01,  2.7529e-01,  2.7099e-01, -5.1742e-01]]],\n",
      "\n",
      "\n",
      "        [[[-7.7916e-03, -4.7438e-02,  1.3850e-01, -7.6883e-02],\n",
      "          [ 1.3774e-01,  1.5530e-02,  4.6466e-02,  3.9620e-02],\n",
      "          [ 5.2241e-02, -1.3082e-01, -3.4331e-02, -2.5024e-02],\n",
      "          [ 1.1675e-01,  8.9918e-02,  1.7768e-01,  4.9570e-02]]]],\n",
      "       requires_grad=True)\n",
      "3 patch_embed.proj.bias Parameter containing:\n",
      "tensor([ 0.0704, -0.0958,  0.0960, -0.1136, -0.0455,  0.1074, -0.0340, -0.0641,\n",
      "         0.1232,  0.1210,  0.0131, -0.0042, -0.1069, -0.0412,  0.1474,  0.2029,\n",
      "         0.1472, -0.1134,  0.1594,  0.0341, -0.0956,  0.0933,  0.1182,  0.0873,\n",
      "         0.1009,  0.0542, -0.0135, -0.1961, -0.0439, -0.2220,  0.0725, -0.0467],\n",
      "       requires_grad=True)\n",
      "4 blocks.0.norm1.weight Parameter containing:\n",
      "tensor([0.8028, 0.6435, 0.7784, 1.0782, 0.9507, 0.9770, 0.9585, 0.6884, 0.8810,\n",
      "        0.8946, 1.0187, 0.8027, 0.6557, 0.9335, 0.7398, 0.6996, 0.5787, 1.0142,\n",
      "        0.6749, 0.8042, 1.0120, 0.8335, 0.7414, 0.7783, 0.8870, 0.9532, 0.7182,\n",
      "        0.6576, 0.7937, 0.7037, 0.9637, 0.8184], requires_grad=True)\n",
      "5 blocks.0.norm1.bias Parameter containing:\n",
      "tensor([ 0.0806, -0.0461, -0.0847,  0.0948, -0.0193,  0.0093, -0.0345,  0.0653,\n",
      "         0.0010, -0.0307,  0.0376, -0.1875,  0.0772,  0.0402, -0.0574,  0.0606,\n",
      "        -0.1304, -0.0254,  0.0138, -0.0916,  0.0589,  0.0082,  0.0370, -0.0547,\n",
      "         0.0179, -0.0108,  0.0143, -0.0682,  0.1235,  0.0948, -0.0655,  0.0040],\n",
      "       requires_grad=True)\n",
      "6 blocks.0.attn.qkv.weight Parameter containing:\n",
      "tensor([[-0.6157,  0.1359, -0.3927,  ..., -0.0914, -0.1215, -0.0668],\n",
      "        [-0.0548,  0.0630,  0.3043,  ...,  0.0437,  0.1184, -0.0048],\n",
      "        [-0.0569,  0.0738, -0.0500,  ..., -0.2929,  0.0228, -0.1211],\n",
      "        ...,\n",
      "        [-0.1001, -0.1904, -0.0895,  ...,  0.0732, -0.0094,  0.4558],\n",
      "        [ 0.1911,  0.1628, -0.1856,  ..., -0.1474, -0.1091, -0.1642],\n",
      "        [ 0.0961, -0.0473, -0.1628,  ..., -0.2397, -0.1357, -0.0134]],\n",
      "       requires_grad=True)\n",
      "7 blocks.0.attn.qkv.bias Parameter containing:\n",
      "tensor([ 7.4507e-02,  5.2139e-02, -4.8534e-01, -9.8150e-02,  1.4309e-01,\n",
      "        -4.5419e-01, -4.0607e-01, -3.4089e-01, -4.5833e-01, -4.2149e-01,\n",
      "         7.5312e-01,  1.1982e-01, -3.1671e-01, -2.4060e-01,  3.2204e-01,\n",
      "         3.6732e-01,  5.1658e-01, -6.1340e-02, -9.1437e-03,  2.1246e-01,\n",
      "         7.5220e-02, -5.5866e-01, -2.4227e-01,  3.0989e-02, -1.0168e-01,\n",
      "        -2.5245e-01,  4.6506e-01, -4.6430e-01,  5.0252e-01,  3.0739e-01,\n",
      "         3.0603e-02, -2.0222e-01, -1.3067e-01, -1.5128e-01, -3.4830e-02,\n",
      "        -1.2728e-01, -7.4746e-02,  1.7766e-01,  9.2772e-02, -1.4516e-01,\n",
      "        -1.8100e-01,  1.4847e-01,  1.2484e-01, -3.3221e-02,  2.5214e-02,\n",
      "         1.4210e-01, -1.4592e-01, -4.8739e-04,  3.0039e-02,  2.2110e-02,\n",
      "         5.1880e-02, -8.3391e-02,  1.5203e-01,  5.9182e-02, -5.6585e-02,\n",
      "        -1.1340e-01,  7.5753e-02, -8.0926e-02, -1.0791e-01, -2.6689e-02,\n",
      "        -9.5678e-02, -7.6443e-02,  1.5617e-01,  1.7518e-01,  1.2988e-01,\n",
      "        -1.5497e-01, -1.1162e-01, -1.6506e-01, -2.5490e-02, -1.2107e-01,\n",
      "         1.9446e-01, -5.0622e-03,  8.7188e-02, -3.7389e-03, -3.3297e-02,\n",
      "        -8.8440e-02,  6.8180e-02, -2.8350e-02,  3.3363e-02, -1.3584e-01,\n",
      "         1.3060e-02, -4.5568e-02,  1.1397e-02, -7.6570e-02,  3.2440e-02,\n",
      "        -7.5963e-02,  1.0069e-01,  3.7141e-02, -1.5183e-01, -1.0107e-02,\n",
      "         3.7132e-02,  4.5666e-02,  1.6060e-01, -2.2404e-02, -5.1604e-02,\n",
      "        -1.4338e-02], requires_grad=True)\n",
      "8 blocks.0.attn.proj.weight Parameter containing:\n",
      "tensor([[ 0.1311,  0.0185, -0.1605,  ..., -0.0595,  0.2479, -0.2342],\n",
      "        [ 0.0326, -0.1274, -0.1007,  ..., -0.2089, -0.1152,  0.0115],\n",
      "        [-0.2074, -0.2478, -0.0830,  ...,  0.0765, -0.0896, -0.3899],\n",
      "        ...,\n",
      "        [ 0.0393,  0.2791,  0.0637,  ...,  0.1395, -0.2090,  0.2195],\n",
      "        [-0.2204,  0.0586, -0.2772,  ...,  0.1143, -0.2222, -0.1691],\n",
      "        [-0.0275,  0.0048, -0.0972,  ...,  0.0453,  0.0188, -0.0676]],\n",
      "       requires_grad=True)\n",
      "9 blocks.0.attn.proj.bias Parameter containing:\n",
      "tensor([ 0.1003, -0.0709,  0.0421, -0.0358,  0.0579, -0.0020, -0.0769,  0.1425,\n",
      "        -0.0112, -0.0567, -0.1276,  0.0237,  0.0521, -0.0545,  0.1332, -0.0764,\n",
      "         0.0351, -0.0605, -0.1354, -0.0866,  0.0393,  0.0177,  0.0348,  0.1743,\n",
      "        -0.0002,  0.0340, -0.0327,  0.1045,  0.0239, -0.0197,  0.0231,  0.0218],\n",
      "       requires_grad=True)\n",
      "10 blocks.0.norm2.weight Parameter containing:\n",
      "tensor([0.8340, 0.7879, 1.0940, 0.9377, 1.0825, 0.8377, 1.0440, 1.0277, 0.9114,\n",
      "        0.9482, 0.7378, 1.0467, 0.9812, 1.0149, 0.9597, 1.0450, 0.8403, 0.9026,\n",
      "        0.8345, 0.8893, 0.8761, 0.9655, 0.7507, 0.9669, 0.8203, 1.0331, 0.9013,\n",
      "        0.9361, 0.8041, 0.9222, 0.8752, 1.0068], requires_grad=True)\n",
      "11 blocks.0.norm2.bias Parameter containing:\n",
      "tensor([ 0.0540,  0.0164,  0.2355, -0.1426,  0.0401,  0.1178,  0.0684,  0.1454,\n",
      "         0.0656,  0.2436,  0.0279,  0.1417,  0.1647, -0.0904,  0.0457, -0.1280,\n",
      "         0.0222, -0.0365, -0.0489, -0.0672, -0.0678, -0.1821,  0.0874,  0.1974,\n",
      "        -0.2027, -0.1363,  0.0220,  0.0502, -0.0982, -0.0536, -0.0912, -0.0898],\n",
      "       requires_grad=True)\n",
      "12 blocks.0.mlp.fc1.weight Parameter containing:\n",
      "tensor([[-0.2059,  0.1344, -0.1839,  0.4697,  0.0216, -0.0839, -0.3724, -0.0497,\n",
      "         -0.1632,  0.1081, -0.1453,  0.1279, -0.1121, -0.3249, -0.2738, -0.0046,\n",
      "          0.3463, -0.2539,  0.0119,  0.0570,  0.3042,  0.2603, -0.1928, -0.1277,\n",
      "          0.2174, -0.2015, -0.1354,  0.1322,  0.1614,  0.0277, -0.0392,  0.0628],\n",
      "        [ 0.0082, -0.1270,  0.0379, -0.1055,  0.2248, -0.0442, -0.1270, -0.0226,\n",
      "          0.0860, -0.1774,  0.1153, -0.2519, -0.4275,  0.1619,  0.1780,  0.1645,\n",
      "          0.1400, -0.0699,  0.1114,  0.1022,  0.1474,  0.1573,  0.1232, -0.0242,\n",
      "          0.1677,  0.0663,  0.1491, -0.1034,  0.0984, -0.2747,  0.0631, -0.1509],\n",
      "        [-0.0613,  0.0864, -0.2479,  0.1742, -0.3920,  0.0616, -0.2166, -0.1571,\n",
      "         -0.2779, -0.1418, -0.0113, -0.0257,  0.1582,  0.1854, -0.2192,  0.1009,\n",
      "         -0.1091,  0.2436, -0.0920, -0.1480,  0.0935, -0.1025, -0.0931, -0.1640,\n",
      "         -0.1786, -0.2468, -0.1921,  0.1893,  0.0383,  0.3511,  0.0848,  0.1665],\n",
      "        [-0.2926,  0.1517,  0.1194,  0.0757,  0.0943, -0.2653,  0.0171,  0.3073,\n",
      "         -0.1366, -0.3087,  0.1370, -0.5044,  0.0919, -0.0406, -0.0583,  0.0040,\n",
      "         -0.1060, -0.0743,  0.0774,  0.0815,  0.1808,  0.4184,  0.0582, -0.1950,\n",
      "         -0.0287,  0.1775, -0.2231, -0.2389, -0.1081, -0.1142,  0.1214,  0.0526],\n",
      "        [-0.1473, -0.1794, -0.1771,  0.1634,  0.1862, -0.2318,  0.2329,  0.1363,\n",
      "          0.1742, -0.2610,  0.0617,  0.1682, -0.1994,  0.1734,  0.0640, -0.0359,\n",
      "         -0.0898, -0.0735,  0.0041,  0.3424, -0.0785, -0.1362, -0.0999, -0.1859,\n",
      "         -0.0465,  0.2075,  0.1664,  0.0435, -0.0433,  0.1570,  0.0604,  0.2076],\n",
      "        [ 0.0785, -0.0422,  0.0133,  0.0206, -0.0276,  0.1500, -0.1608, -0.1755,\n",
      "          0.2429, -0.2170,  0.1328, -0.0747,  0.0682, -0.0561,  0.2059,  0.2374,\n",
      "          0.1436,  0.0814, -0.2793, -0.2256, -0.2996,  0.1230,  0.0170,  0.0800,\n",
      "          0.1703,  0.2229, -0.0838, -0.1646,  0.3716, -0.0233, -0.2675,  0.1775],\n",
      "        [ 0.1518, -0.1212, -0.1043, -0.2299,  0.0574, -0.2277, -0.3058, -0.1616,\n",
      "          0.2092, -0.2489, -0.3868,  0.0769,  0.0059,  0.3013, -0.0861,  0.0516,\n",
      "         -0.0429,  0.0888,  0.2080,  0.0571,  0.0506,  0.2269, -0.1077, -0.1523,\n",
      "          0.1847, -0.1470, -0.2796,  0.0980,  0.0951,  0.1357,  0.1729,  0.2075],\n",
      "        [-0.0686, -0.1963, -0.3646, -0.0758,  0.0207, -0.0782, -0.1539, -0.1276,\n",
      "          0.1548,  0.0633,  0.1350,  0.0435,  0.0523,  0.1437, -0.2433,  0.3254,\n",
      "         -0.1733,  0.0858,  0.1160,  0.2008, -0.1581,  0.0569, -0.0449, -0.4777,\n",
      "          0.2606, -0.0781,  0.0662,  0.1234,  0.0974, -0.0236,  0.0513,  0.0902],\n",
      "        [-0.0712, -0.1062,  0.1962,  0.0928, -0.0252,  0.2331,  0.2001,  0.0690,\n",
      "         -0.1196,  0.0235, -0.0151, -0.1659, -0.1314,  0.1100,  0.0498,  0.4481,\n",
      "         -0.1552,  0.1412, -0.0090,  0.0593,  0.0111,  0.1353,  0.3283, -0.0843,\n",
      "          0.1941,  0.1192,  0.1649, -0.1073,  0.0285,  0.0789,  0.2201, -0.1493],\n",
      "        [ 0.2456,  0.0113, -0.6227, -0.0273,  0.0823, -0.0114, -0.2620, -0.4350,\n",
      "          0.0450,  0.2472, -0.0349, -0.0357,  0.1138, -0.0551, -0.1248, -0.1277,\n",
      "         -0.1659,  0.0533, -0.1068, -0.1477,  0.0571, -0.0851,  0.0301,  0.1060,\n",
      "          0.1814, -0.1143, -0.0486,  0.2785, -0.0567, -0.0813, -0.0345,  0.2362],\n",
      "        [ 0.0805,  0.1362, -0.0210,  0.1700,  0.1190, -0.1027, -0.1586, -0.0209,\n",
      "         -0.1211, -0.1732,  0.1011, -0.2371,  0.0673, -0.0028, -0.2229,  0.0302,\n",
      "          0.1547, -0.2671,  0.2169,  0.0360, -0.1778,  0.0831, -0.1278,  0.0234,\n",
      "          0.1686,  0.4048, -0.0611, -0.1650,  0.1732, -0.1268, -0.0027, -0.1707],\n",
      "        [-0.1280, -0.2687,  0.0482,  0.2244, -0.3753, -0.0677, -0.0028,  0.2029,\n",
      "         -0.0899, -0.2278, -0.0430, -0.3991, -0.1549,  0.2054, -0.0655, -0.1509,\n",
      "         -0.1044,  0.3017,  0.1998, -0.0942, -0.0774,  0.1908, -0.0898, -0.1570,\n",
      "         -0.1135,  0.1559,  0.1383, -0.3049, -0.0445,  0.1037, -0.2750,  0.2667]],\n",
      "       requires_grad=True)\n",
      "13 blocks.0.mlp.fc1.bias Parameter containing:\n",
      "tensor([-0.0379, -0.1989, -0.2930, -0.2983, -0.1813, -0.2350, -0.0520,  0.1186,\n",
      "        -0.1101, -0.3205, -0.0584, -0.2649], requires_grad=True)\n",
      "14 blocks.0.mlp.fc2.weight Parameter containing:\n",
      "tensor([[ 0.4515,  0.3438, -0.1474,  0.2759, -0.0201, -0.1704,  0.0052,  0.2981,\n",
      "          0.2650, -0.3306, -0.2310, -0.0250],\n",
      "        [-0.1595,  0.0323, -0.0854,  0.1792,  0.0227, -0.2989, -0.2186,  0.1391,\n",
      "          0.2883,  0.5339, -0.2111, -0.1802],\n",
      "        [ 0.1312, -0.0433, -0.0731, -0.1400,  0.1882, -0.2104, -0.3622, -0.1504,\n",
      "          0.0464,  0.3631, -0.3010, -0.0455],\n",
      "        [-0.6444,  0.3364,  0.2742, -0.0358, -0.3252,  0.1017,  0.2726,  0.4481,\n",
      "          0.1149, -0.1650,  0.1069,  0.0443],\n",
      "        [-0.0256, -0.1847,  0.1978, -0.1537, -0.3040, -0.0668,  0.3183,  0.3663,\n",
      "          0.2945, -0.3349, -0.1642, -0.0622],\n",
      "        [-0.3397, -0.0844,  0.1653,  0.2532,  0.0658, -0.2675, -0.4699,  0.0226,\n",
      "         -0.3154, -0.1450, -0.1177, -0.3172],\n",
      "        [-0.1309, -0.4475,  0.6556,  0.3264,  0.2736, -0.0657,  0.0086,  0.0671,\n",
      "         -0.1494,  0.1711,  0.0794, -0.4562],\n",
      "        [-0.1247, -0.1135, -0.0706, -0.3005, -0.0028,  0.0541,  0.6781,  0.1511,\n",
      "          0.2846,  0.3961, -0.1776, -0.3369],\n",
      "        [-0.1457, -0.0658, -0.1340,  0.3714,  0.0619, -0.1591, -0.4584,  0.0931,\n",
      "          0.3551,  0.2650,  0.5257,  0.0677],\n",
      "        [ 0.3180,  0.1198,  0.2347,  0.3142,  0.2441,  0.0752,  0.0399,  0.2092,\n",
      "          0.3422, -0.2206,  0.0957, -0.1888],\n",
      "        [ 0.0113, -0.3790,  0.0819, -0.0334,  0.0864,  0.3669,  0.1089,  0.6666,\n",
      "         -0.0419, -0.1692, -0.6812, -0.3281],\n",
      "        [ 0.3018,  0.1292,  0.1873,  0.3139, -0.2693, -0.2195,  0.2244,  0.1006,\n",
      "         -0.3194, -0.1264,  0.0247,  0.0170],\n",
      "        [-0.0726,  0.3203,  0.3524,  0.1885,  0.2897, -0.0086,  0.0214, -0.1309,\n",
      "         -0.1221,  0.1326,  0.4928, -0.1722],\n",
      "        [ 0.1748, -0.3237, -0.1709,  0.2859,  0.0345,  0.0525, -0.2781, -0.1097,\n",
      "          0.0321,  0.3391, -0.3413,  0.5300],\n",
      "        [ 0.1902,  0.0077,  0.0456,  0.0230,  0.3882, -0.2266, -0.1188, -0.3516,\n",
      "          0.3416, -0.1391,  0.1933, -0.2831],\n",
      "        [ 0.0914, -0.3193, -0.2547, -0.1327, -0.0868, -0.1509, -0.3838, -0.2305,\n",
      "          0.0851,  0.2456, -0.0516,  0.0170],\n",
      "        [-0.2309,  0.2300,  0.1265, -0.3100, -0.3507,  0.2580, -0.2199,  0.0054,\n",
      "          0.2065, -0.3838, -0.1518,  0.3083],\n",
      "        [-0.1167,  0.0890,  0.1203,  0.0537, -0.0395,  0.0648, -0.0035, -0.1746,\n",
      "          0.0779,  0.1736,  0.0783,  0.6006],\n",
      "        [ 0.0300, -0.1391, -0.1555, -0.2934, -0.2994,  0.0642, -0.3236,  0.1502,\n",
      "          0.1327, -0.0747, -0.1209,  0.4594],\n",
      "        [-0.1066,  0.3050,  0.4355,  0.0732, -0.3322, -0.1585,  0.1400, -0.3600,\n",
      "          0.2072, -0.1668,  0.2531, -0.1298],\n",
      "        [ 0.0267, -0.3940, -0.1732, -0.4057,  0.4457,  0.1030, -0.3269, -0.0207,\n",
      "         -0.1292, -0.0017, -0.4243,  0.4166],\n",
      "        [-0.0188, -0.0181,  0.4368, -0.2039, -0.3579,  0.3522,  0.1199, -0.1614,\n",
      "         -0.1138,  0.2088, -0.0993,  0.3020],\n",
      "        [ 0.2818,  0.2804, -0.1744, -0.0735,  0.5124,  0.3055,  0.0187, -0.3184,\n",
      "         -0.3437, -0.1604,  0.0709, -0.2144],\n",
      "        [ 0.1064,  0.2671,  0.1543, -0.1417, -0.1003, -0.3056,  0.2919,  0.2772,\n",
      "         -0.2699, -0.0023, -0.1212,  0.3031],\n",
      "        [ 0.0417, -0.1154,  0.0667,  0.0083,  0.2706, -0.3167, -0.1297,  0.0776,\n",
      "         -0.1519, -0.1267, -0.1078, -0.2074],\n",
      "        [-0.4242, -0.0295,  0.6543,  0.0352, -0.5353, -0.1908,  0.4431,  0.1121,\n",
      "         -0.2913, -0.2025, -0.2469,  0.0036],\n",
      "        [ 0.2303,  0.3616, -0.1852,  0.6359,  0.0756, -0.2406, -0.5596, -0.2694,\n",
      "          0.1373,  0.5969,  0.2876, -0.3990],\n",
      "        [ 0.1713,  0.2252, -0.0121,  0.2362, -0.0773,  0.2629, -0.1502,  0.1371,\n",
      "          0.0616, -0.4175,  0.0869,  0.0329],\n",
      "        [ 0.1486, -0.1410, -0.3800,  0.2303,  0.0114, -0.3337,  0.0584, -0.3398,\n",
      "         -0.0814,  0.2321,  0.0527, -0.1978],\n",
      "        [ 0.1494, -0.1054, -0.8103, -0.3863,  0.2437,  0.0956,  0.1931,  0.1680,\n",
      "          0.4117, -0.0523,  0.0118,  0.3482],\n",
      "        [-0.1744,  0.2673, -0.2232, -0.3332, -0.2039,  0.3026,  0.4011, -0.3532,\n",
      "         -0.2273,  0.3089,  0.0017,  0.4026],\n",
      "        [-0.0496,  0.3825,  0.0776, -0.3974, -0.0673,  0.3955,  0.2510,  0.1775,\n",
      "          0.2903, -0.0021,  0.1925,  0.0488]], requires_grad=True)\n",
      "15 blocks.0.mlp.fc2.bias Parameter containing:\n",
      "tensor([-0.0338, -0.3155,  0.3437,  0.1593, -0.0177,  0.3708, -0.1833,  0.0013,\n",
      "        -0.3046,  0.0940, -0.1468, -0.0996,  0.2428,  0.0054, -0.1256,  0.2749,\n",
      "        -0.0415, -0.2383, -0.0041, -0.2631,  0.1357,  0.3873,  0.0951,  0.1777,\n",
      "         0.4755,  0.2133, -0.1235, -0.1048, -0.0032,  0.1739, -0.1564, -0.0072],\n",
      "       requires_grad=True)\n",
      "16 blocks.1.norm1.weight Parameter containing:\n",
      "tensor([0.9112, 0.6938, 0.7860, 1.0521, 0.9971, 0.8783, 0.7581, 0.7770, 0.7644,\n",
      "        0.6902, 0.8510, 0.8240, 0.8070, 0.9832, 0.7471, 0.8810, 0.8082, 1.0408,\n",
      "        0.7364, 0.7625, 0.9815, 0.8114, 0.7349, 0.7424, 0.9656, 1.0546, 0.8445,\n",
      "        0.8689, 0.9333, 0.8689, 0.8158, 1.0010], requires_grad=True)\n",
      "17 blocks.1.norm1.bias Parameter containing:\n",
      "tensor([ 0.1644,  0.1836, -0.0890, -0.0022,  0.0744, -0.2773, -0.0216, -0.0289,\n",
      "         0.0948, -0.0813, -0.0310,  0.0393, -0.2500, -0.0646,  0.0411, -0.0578,\n",
      "         0.0342,  0.1180,  0.0768,  0.1103, -0.0542,  0.0811, -0.0231, -0.0205,\n",
      "        -0.1670,  0.0191, -0.0831,  0.1088,  0.1952, -0.0719,  0.0814,  0.0463],\n",
      "       requires_grad=True)\n",
      "18 blocks.1.attn.qkv.weight Parameter containing:\n",
      "tensor([[ 4.8761e-02,  3.0079e-01, -1.2890e-01,  ..., -1.0424e-01,\n",
      "         -7.0701e-02, -2.0378e-01],\n",
      "        [-3.8205e-02,  2.8075e-01, -3.3156e-03,  ...,  9.4047e-02,\n",
      "          2.4680e-01,  5.9065e-02],\n",
      "        [-2.4429e-02, -1.8964e-01, -6.4814e-02,  ...,  2.8698e-01,\n",
      "          9.5497e-02, -2.5816e-02],\n",
      "        ...,\n",
      "        [-1.2362e-01,  1.5709e-01, -3.5374e-04,  ...,  1.1908e-01,\n",
      "          4.2620e-02, -1.1073e-01],\n",
      "        [ 9.4676e-02, -1.8427e-01,  2.2650e-01,  ..., -7.3616e-02,\n",
      "          1.4642e-01, -5.2613e-01],\n",
      "        [-9.1634e-02, -2.5451e-01,  2.6381e-01,  ..., -1.7820e-01,\n",
      "         -2.7483e-02, -2.1962e-01]], requires_grad=True)\n",
      "19 blocks.1.attn.qkv.bias Parameter containing:\n",
      "tensor([ 0.1452, -0.0353, -0.6477, -0.4390, -0.1785,  0.3673,  0.1104, -0.0140,\n",
      "         0.4372,  0.0489, -0.2669, -0.0944,  0.4801, -0.0812,  0.1869,  0.3913,\n",
      "        -0.7943, -0.3567,  0.0642, -0.3622, -0.3535,  0.1739,  0.3527, -0.2275,\n",
      "         0.4397, -0.6229, -0.4256, -0.7175,  0.4243, -0.2060,  0.8022, -0.0307,\n",
      "        -0.0673, -0.0206,  0.0583,  0.1513, -0.1605,  0.0221,  0.0566,  0.1253,\n",
      "         0.1557, -0.0878,  0.0403,  0.1483,  0.0079, -0.0150,  0.1031,  0.0261,\n",
      "         0.1841,  0.1694,  0.0996, -0.0037, -0.0879, -0.1018, -0.0059,  0.1193,\n",
      "        -0.1581,  0.0415,  0.1874,  0.1094,  0.0088, -0.0155, -0.1819,  0.0317,\n",
      "         0.0321, -0.0562,  0.0678, -0.1416,  0.0740, -0.0521, -0.0287, -0.0122,\n",
      "         0.1291,  0.0674,  0.0376,  0.1099, -0.0369, -0.1252, -0.0759, -0.1215,\n",
      "        -0.0471, -0.1185, -0.1063, -0.0241, -0.2486, -0.1122, -0.0338, -0.1103,\n",
      "        -0.0108, -0.0040, -0.1253,  0.2394,  0.0840, -0.2998,  0.1722,  0.0217],\n",
      "       requires_grad=True)\n",
      "20 blocks.1.attn.proj.weight Parameter containing:\n",
      "tensor([[-0.2540,  0.1249,  0.0619,  ..., -0.5075,  0.0960,  0.1402],\n",
      "        [ 0.0899, -0.2236,  0.5126,  ...,  0.0639, -0.0147, -0.2931],\n",
      "        [ 0.2450,  0.2197,  0.0827,  ..., -0.0550,  0.2334, -0.0492],\n",
      "        ...,\n",
      "        [ 0.1810,  0.1080,  0.2359,  ...,  0.2409,  0.0275, -0.1698],\n",
      "        [ 0.1957,  0.2459,  0.0608,  ...,  0.1042,  0.1116, -0.0872],\n",
      "        [-0.0947,  0.2448,  0.3019,  ..., -0.4085,  0.2739,  0.0979]],\n",
      "       requires_grad=True)\n",
      "21 blocks.1.attn.proj.bias Parameter containing:\n",
      "tensor([-0.1562, -0.0342,  0.0499, -0.1659,  0.1131,  0.1968, -0.0976, -0.0093,\n",
      "         0.2283, -0.0981,  0.1171, -0.1401, -0.1224, -0.1163,  0.0593,  0.0687,\n",
      "         0.0077, -0.2305, -0.2588, -0.1308,  0.2126, -0.0765,  0.0548,  0.1545,\n",
      "         0.1829,  0.1529,  0.2687, -0.0998, -0.1412, -0.0457, -0.0947, -0.1234],\n",
      "       requires_grad=True)\n",
      "22 blocks.1.norm2.weight Parameter containing:\n",
      "tensor([0.9816, 0.9818, 1.0605, 1.0799, 0.8545, 0.9169, 0.9055, 0.7567, 0.9051,\n",
      "        1.0029, 0.9577, 0.8432, 1.0699, 0.7681, 1.1411, 0.7830, 0.6784, 0.8776,\n",
      "        0.8465, 1.0859, 0.8195, 1.0814, 0.9740, 0.8263, 0.9242, 1.0569, 1.0080,\n",
      "        1.0157, 0.7417, 0.9690, 1.1733, 0.8811], requires_grad=True)\n",
      "23 blocks.1.norm2.bias Parameter containing:\n",
      "tensor([-0.1479,  0.0927, -0.0743, -0.0253,  0.0259,  0.0425, -0.1663,  0.0427,\n",
      "         0.1462, -0.1406, -0.0130,  0.1049, -0.0385, -0.1241,  0.0727, -0.0307,\n",
      "        -0.3007,  0.1949,  0.2459,  0.0247,  0.0018, -0.0993,  0.0156, -0.0188,\n",
      "        -0.2008, -0.0444,  0.2008,  0.0942, -0.1479, -0.0125,  0.1896, -0.0470],\n",
      "       requires_grad=True)\n",
      "24 blocks.1.mlp.fc1.weight Parameter containing:\n",
      "tensor([[ 2.2566e-01, -2.2902e-01,  2.8224e-01,  2.9445e-01,  1.0976e-01,\n",
      "          1.3507e-01, -2.3499e-01, -2.4926e-02,  2.1557e-01, -2.2420e-01,\n",
      "          6.0556e-02,  4.1219e-02, -1.6752e-02,  1.9373e-01, -3.1812e-01,\n",
      "         -2.1246e-01,  4.0499e-02,  1.2406e-01, -1.0525e-01,  4.5609e-01,\n",
      "         -1.0919e-01, -7.1773e-02,  9.7036e-03, -1.4874e-01,  3.5059e-02,\n",
      "          4.0028e-01,  2.2285e-01, -4.2473e-02,  1.2930e-01, -2.4989e-02,\n",
      "          4.4369e-02,  1.8071e-03],\n",
      "        [ 1.3356e-01, -2.2616e-01,  1.2193e-01,  1.1965e-02,  2.2229e-02,\n",
      "         -3.6072e-02, -1.8553e-01,  2.4601e-01,  2.6349e-01,  1.8461e-01,\n",
      "          1.6068e-02, -3.4483e-02, -1.2692e-01,  9.5002e-03,  1.8217e-01,\n",
      "         -1.8928e-01,  1.9069e-01, -3.1979e-02, -1.2976e-01,  4.1175e-01,\n",
      "          9.5183e-02, -2.1563e-01, -5.2720e-02,  4.3049e-02,  2.7102e-04,\n",
      "         -1.2867e-01,  1.3899e-01,  1.4297e-01, -1.8540e-01, -1.1036e-01,\n",
      "         -2.0055e-01, -8.2201e-03],\n",
      "        [ 1.6484e-01, -2.9195e-01,  2.7029e-01,  2.4533e-01, -1.3253e-01,\n",
      "          3.3621e-01,  3.0846e-01,  5.4735e-02, -9.3229e-02,  1.7794e-01,\n",
      "         -1.8205e-01,  5.5004e-02,  2.7550e-01, -5.0777e-02, -2.6523e-01,\n",
      "         -2.8972e-03, -2.0438e-02, -1.1821e-01, -6.4798e-03, -1.5403e-01,\n",
      "          5.5594e-03,  5.4912e-01, -8.2957e-02, -2.6884e-02,  1.6981e-01,\n",
      "         -1.8962e-01, -6.3672e-02, -1.0625e-01,  1.6449e-01, -5.4527e-02,\n",
      "         -4.2736e-01, -2.1654e-01],\n",
      "        [-1.7737e-01, -5.5917e-02,  7.7815e-03, -1.0037e-01,  2.2737e-02,\n",
      "          3.5324e-02, -7.4830e-02, -1.9300e-02, -2.1853e-01,  4.2412e-02,\n",
      "         -4.1423e-02, -6.3001e-02,  2.7539e-01,  1.3024e-01,  1.9081e-01,\n",
      "          8.1449e-02,  9.3192e-02,  3.4574e-02, -3.4903e-01,  2.9625e-01,\n",
      "         -2.2483e-01, -1.4101e-01,  2.3745e-01,  1.9790e-01,  3.0060e-02,\n",
      "         -6.4889e-02, -3.8313e-01, -2.2191e-02,  1.0916e-01,  1.1890e-01,\n",
      "          2.1495e-01, -2.0345e-01],\n",
      "        [-1.8164e-01,  8.7531e-02, -2.3689e-01,  6.2997e-02,  1.8212e-01,\n",
      "          2.8944e-02,  1.4994e-01, -7.7467e-02, -1.0541e-01, -1.6743e-01,\n",
      "          2.9613e-01, -2.6613e-01, -4.8716e-02,  3.2512e-02,  1.6229e-01,\n",
      "          1.4844e-01,  1.2464e-01, -1.5991e-01,  2.4722e-01, -3.1665e-01,\n",
      "         -1.5782e-01, -2.4848e-01,  2.1935e-01, -1.1068e-01,  7.0942e-02,\n",
      "          4.0307e-01,  6.7367e-02, -1.4201e-01, -5.0786e-02,  2.9555e-03,\n",
      "          1.5380e-01,  2.6105e-01],\n",
      "        [ 2.0989e-01,  2.3283e-01,  7.1698e-02, -1.6162e-01, -2.6626e-01,\n",
      "         -4.2702e-02,  2.3409e-01, -6.1769e-02, -1.2087e-01,  1.4493e-01,\n",
      "         -2.5735e-04,  1.9666e-01,  4.0045e-02,  1.4155e-02, -2.4210e-01,\n",
      "          1.9537e-01, -4.2582e-02,  1.0674e-01,  1.7938e-01, -1.3896e-01,\n",
      "          5.6009e-02,  1.4689e-01, -1.2440e-01, -1.6934e-01, -9.1731e-02,\n",
      "         -1.0408e-01, -2.9835e-01, -7.8341e-03, -4.5339e-03, -2.4665e-01,\n",
      "          1.6163e-01,  1.7626e-01],\n",
      "        [-5.6575e-02,  1.6724e-01, -2.6568e-01, -9.8187e-02,  6.1935e-02,\n",
      "         -1.5449e-01, -5.1369e-02,  4.1909e-02,  2.1855e-01,  9.3316e-02,\n",
      "         -8.9215e-02,  2.4640e-02, -2.0053e-01, -2.5990e-01,  3.4395e-01,\n",
      "         -7.7665e-02, -7.3709e-02, -1.8349e-02, -2.5613e-02, -6.2081e-02,\n",
      "          3.5508e-01, -1.1128e-01, -1.7892e-01,  2.8313e-01,  1.3147e-01,\n",
      "         -1.1647e-02,  5.6471e-02,  2.0249e-01, -3.4413e-02, -4.2123e-01,\n",
      "         -2.6091e-02,  5.5524e-02],\n",
      "        [ 7.1052e-02, -7.3373e-02, -4.6525e-02,  1.7301e-01,  4.1358e-01,\n",
      "         -1.1707e-01,  8.5061e-02, -2.7710e-02,  9.2555e-02, -9.7109e-02,\n",
      "         -1.8753e-01, -2.8414e-01, -9.1652e-02,  1.3468e-01,  3.3949e-01,\n",
      "          7.6021e-03,  1.3864e-01, -3.8602e-01,  5.2392e-02, -2.2653e-02,\n",
      "          1.4822e-01,  9.8596e-02, -2.0905e-01, -1.5703e-01,  4.5825e-01,\n",
      "          7.8166e-03, -5.7626e-02, -2.6357e-01,  3.3220e-01, -3.6978e-01,\n",
      "         -9.5335e-02,  1.0533e-01],\n",
      "        [ 6.8326e-02,  2.3268e-01, -2.9751e-01,  2.5613e-01, -9.9048e-02,\n",
      "         -1.3068e-01,  3.0710e-01,  1.3074e-02,  1.5578e-02, -2.5078e-01,\n",
      "         -2.7411e-01, -1.2029e-01, -1.6170e-01, -8.2960e-02,  8.8240e-02,\n",
      "          3.0550e-01, -5.1459e-04, -6.3984e-02,  1.0870e-01, -9.8040e-02,\n",
      "         -1.9614e-02,  1.2954e-01,  5.9805e-02, -1.0561e-01, -7.2377e-02,\n",
      "          1.2135e-01, -4.5175e-02,  2.6387e-01,  6.5816e-02, -4.2864e-02,\n",
      "          7.8550e-03,  2.0784e-01],\n",
      "        [ 2.7390e-01, -9.6255e-02, -8.2654e-02,  7.4978e-02, -8.6015e-02,\n",
      "         -3.6323e-01,  7.6572e-02, -2.1919e-02,  4.2197e-02,  3.0623e-01,\n",
      "         -5.5411e-02,  1.7765e-01, -2.0089e-01, -1.1879e-01,  2.3022e-01,\n",
      "          2.5888e-02,  3.3538e-01, -5.0464e-02, -1.2975e-01,  4.7875e-02,\n",
      "         -1.1411e-01,  9.7843e-02, -5.4572e-02,  1.7879e-01,  1.4717e-02,\n",
      "         -1.7557e-01, -3.2579e-01, -2.2282e-01,  1.1385e-01, -2.1433e-01,\n",
      "         -2.7394e-01, -7.4185e-02],\n",
      "        [ 3.2455e-01,  5.9115e-02,  2.1182e-02,  3.3027e-01, -1.5147e-01,\n",
      "          9.7979e-02,  2.0487e-01, -3.0217e-01, -4.2254e-02, -1.5344e-01,\n",
      "          1.6235e-01, -6.0145e-03, -6.2884e-02,  2.8787e-01, -2.0924e-01,\n",
      "         -7.8431e-02,  8.1567e-02,  4.5928e-02,  7.1497e-03,  1.9928e-01,\n",
      "         -2.5353e-02, -5.1211e-02, -8.3738e-02, -1.1998e-01, -2.2855e-01,\n",
      "          2.0016e-02,  2.9864e-03,  2.0944e-01,  1.2315e-01,  1.4969e-02,\n",
      "         -3.6800e-01, -1.7868e-01],\n",
      "        [ 1.0186e-01,  6.6930e-02, -2.3996e-01, -1.5014e-01, -6.6477e-02,\n",
      "         -6.1186e-02, -2.9891e-02,  1.0569e-01, -3.0555e-01,  4.7174e-03,\n",
      "         -1.4867e-01,  1.9382e-01,  2.5695e-01,  1.1381e-02, -8.1832e-03,\n",
      "         -2.6682e-02,  7.8677e-02,  1.6941e-01, -2.0090e-01,  1.9675e-01,\n",
      "         -2.0827e-02,  2.4313e-02,  2.6040e-01, -4.3358e-03, -7.0514e-02,\n",
      "         -2.6012e-01, -1.1276e-01,  3.6606e-01,  8.9805e-02,  2.2895e-02,\n",
      "         -6.7795e-02, -1.7993e-01]], requires_grad=True)\n",
      "25 blocks.1.mlp.fc1.bias Parameter containing:\n",
      "tensor([-0.1865,  0.0861,  0.1088, -0.0244, -0.1403, -0.1099, -0.0995, -0.3531,\n",
      "        -0.0461, -0.2804, -0.1889, -0.1640], requires_grad=True)\n",
      "26 blocks.1.mlp.fc2.weight Parameter containing:\n",
      "tensor([[-1.3142e-01, -1.1695e-01,  5.1709e-02,  1.5346e-01, -1.8862e-01,\n",
      "          1.9450e-01,  4.3834e-01, -8.7157e-02,  4.6269e-01, -2.2868e-01,\n",
      "         -1.2502e-02, -1.9324e-01],\n",
      "        [-7.3904e-02, -1.0147e-01,  1.9686e-01,  2.1895e-01, -2.5819e-01,\n",
      "          2.2958e-01, -4.0280e-01,  4.0248e-01,  6.5181e-02,  3.6892e-01,\n",
      "         -4.6117e-01, -3.4451e-01],\n",
      "        [ 1.4568e-01,  2.1724e-01, -2.0369e-01, -4.8949e-02, -1.3568e-01,\n",
      "         -1.2684e-01,  4.6566e-02, -1.5623e-01, -1.3002e-01, -1.5527e-01,\n",
      "          4.7673e-01, -3.1267e-01],\n",
      "        [-1.5607e-01, -6.7670e-02,  3.8228e-01, -2.5736e-01,  2.9365e-01,\n",
      "         -3.9997e-01,  6.5632e-01,  2.4679e-01, -2.1838e-01, -3.5325e-03,\n",
      "          3.7714e-01, -6.0346e-01],\n",
      "        [-1.5258e-01, -4.4044e-01,  3.1951e-01, -1.4120e-01,  1.0769e-01,\n",
      "          2.6817e-02,  8.3597e-02, -4.1405e-01, -3.2460e-02, -1.4864e-02,\n",
      "          4.7437e-03, -1.4062e-01],\n",
      "        [-2.5880e-01, -3.0558e-01, -3.0314e-01, -9.8209e-02, -3.1252e-01,\n",
      "         -3.9932e-02,  1.2867e-01,  2.2379e-01, -1.0807e-01,  9.3175e-02,\n",
      "          1.1182e-01,  3.5349e-01],\n",
      "        [ 1.7205e-01, -1.4350e-01, -2.2566e-01,  8.3888e-02,  4.9333e-02,\n",
      "          1.2376e-01,  4.5486e-01,  3.8847e-01, -2.8081e-01, -6.1651e-02,\n",
      "          1.9131e-02,  3.6003e-02],\n",
      "        [-6.0651e-02, -3.2295e-02,  1.4245e-01,  4.0784e-02, -1.7334e-01,\n",
      "         -2.8189e-01, -8.9176e-02, -2.8122e-01,  8.7167e-02,  1.7442e-01,\n",
      "         -1.3944e-01,  3.5255e-01],\n",
      "        [-2.4050e-01,  1.3849e-01, -1.4009e-01,  3.7889e-01, -1.8774e-01,\n",
      "         -3.7652e-01, -6.2205e-01, -5.6444e-02,  4.8939e-01,  1.2016e-02,\n",
      "          3.2400e-03,  9.9468e-02],\n",
      "        [ 3.9267e-01,  5.2327e-02, -4.3281e-01, -1.7589e-01,  8.8616e-02,\n",
      "          3.7568e-01,  2.2440e-01, -5.0706e-02, -2.1504e-01, -2.2227e-01,\n",
      "         -1.8172e-02,  2.0165e-01],\n",
      "        [ 3.8430e-01, -1.4926e-01,  1.6793e-01,  1.4124e-01, -1.9044e-01,\n",
      "          2.9783e-01,  4.6956e-02,  2.2608e-01, -8.0743e-02, -2.2667e-01,\n",
      "         -5.9908e-01, -2.0156e-01],\n",
      "        [-2.0307e-02, -3.4073e-01, -3.4709e-01, -3.4039e-01, -2.3891e-01,\n",
      "         -6.1369e-03, -1.0339e-01,  2.7270e-01,  4.4782e-01, -2.0194e-01,\n",
      "          8.1620e-02, -3.2716e-01],\n",
      "        [-3.3317e-01,  3.8231e-01,  2.2507e-01,  1.2882e-02, -1.1148e-01,\n",
      "         -1.5036e-01, -2.7317e-01,  4.0211e-01,  1.6809e-02, -1.7810e-01,\n",
      "          5.2719e-02,  2.5402e-01],\n",
      "        [-3.6658e-01, -1.6856e-01, -1.5958e-01,  1.5182e-01, -2.6667e-01,\n",
      "         -2.2934e-01, -4.4534e-02, -4.7903e-01,  3.0752e-01,  4.6659e-01,\n",
      "         -2.0733e-01, -1.5627e-01],\n",
      "        [-1.3580e-01, -5.0379e-02,  9.7451e-02, -1.6881e-01,  2.9657e-01,\n",
      "          3.5185e-01,  3.7581e-01,  4.6678e-01, -8.0608e-01, -2.9279e-02,\n",
      "          8.1039e-03,  1.0266e-01],\n",
      "        [ 1.1878e-03, -1.8729e-01,  1.8849e-01,  6.7173e-02, -1.1166e-01,\n",
      "          4.2889e-05,  3.4180e-01,  4.5976e-01, -1.9287e-01,  1.0604e-01,\n",
      "          4.2516e-01,  1.3997e-01],\n",
      "        [ 3.0889e-02,  7.8755e-02,  5.3533e-02,  2.8694e-01, -5.8572e-02,\n",
      "          1.5098e-02, -7.7496e-03, -2.3674e-02,  1.2645e-01,  1.5503e-01,\n",
      "         -2.0907e-01,  2.0854e-01],\n",
      "        [-9.0568e-03,  2.5294e-02, -2.0981e-01, -2.8108e-01,  7.9200e-03,\n",
      "         -2.7569e-02,  2.8452e-01,  8.1719e-02, -6.3901e-01,  6.8577e-03,\n",
      "          5.8582e-01, -7.6743e-02],\n",
      "        [ 3.7345e-01, -5.0322e-02, -5.8181e-01,  6.1748e-02,  1.1782e-01,\n",
      "          2.3698e-01, -3.6215e-01, -2.9769e-01,  2.2406e-01,  1.0451e-01,\n",
      "         -3.4369e-01,  1.6905e-02],\n",
      "        [-2.1833e-01,  1.7223e-01, -2.7048e-01, -4.0754e-02, -9.9926e-02,\n",
      "          2.5804e-01, -3.9119e-01,  2.8857e-02,  4.3474e-02,  4.1333e-01,\n",
      "          2.0057e-01, -1.4607e-01],\n",
      "        [ 1.4014e-01,  2.0206e-01,  3.5263e-01,  1.2115e-01, -3.0289e-02,\n",
      "         -8.3516e-05, -4.7475e-01,  3.9002e-01,  2.4172e-01,  2.0233e-01,\n",
      "         -5.1078e-01,  1.2619e-01],\n",
      "        [ 1.5556e-01,  1.6455e-01,  4.9661e-01,  1.4500e-01, -5.3061e-02,\n",
      "          2.9797e-02, -3.0420e-02,  3.4435e-01, -1.1084e-01,  2.6901e-01,\n",
      "         -3.6781e-01,  3.5197e-01],\n",
      "        [ 3.9364e-02, -6.2194e-02, -1.9824e-01, -1.7445e-01, -2.7341e-02,\n",
      "         -5.6427e-02,  1.8801e-01,  3.4999e-01, -5.1215e-01,  1.5921e-01,\n",
      "          3.5587e-01, -4.8779e-01],\n",
      "        [-3.8018e-02, -9.0440e-02,  2.4225e-01, -2.2135e-01,  4.4653e-01,\n",
      "          1.6840e-01, -1.3762e-01,  3.6363e-01, -5.8366e-01, -9.7136e-02,\n",
      "         -2.5251e-02, -2.2117e-02],\n",
      "        [ 3.7399e-01,  2.2309e-01,  1.2665e-01,  2.2229e-01,  3.2643e-01,\n",
      "         -5.1543e-02,  1.8413e-01, -5.7484e-01, -1.9625e-01,  3.7326e-02,\n",
      "          1.5916e-01,  1.3493e-01],\n",
      "        [-2.8578e-01,  4.1970e-01,  2.3841e-01,  4.1362e-01,  6.4590e-01,\n",
      "         -1.0597e-01, -5.0158e-01, -5.1644e-01,  5.1754e-01, -1.4164e-01,\n",
      "          2.5267e-01,  1.5671e-01],\n",
      "        [-1.3084e-01, -1.6357e-01, -3.5514e-01, -1.5438e-01, -1.1502e-02,\n",
      "         -1.2605e-01,  6.8672e-02, -3.9171e-01,  3.8789e-05, -7.2843e-01,\n",
      "          3.5853e-01,  1.6645e-01],\n",
      "        [-5.1217e-01,  2.6813e-01,  1.8350e-01, -3.8350e-01, -8.4952e-02,\n",
      "         -2.5671e-02, -6.9348e-02, -9.8626e-02, -1.2311e-02,  1.2347e-01,\n",
      "         -3.1648e-01,  5.6626e-01],\n",
      "        [ 5.3122e-02, -2.3833e-01, -2.4382e-01, -2.1759e-01,  5.3597e-02,\n",
      "         -3.0239e-01, -4.2761e-02, -1.2615e-01,  4.6728e-01,  1.5351e-01,\n",
      "         -4.6001e-01,  9.6370e-02],\n",
      "        [ 5.8824e-01, -9.5586e-02,  1.7496e-01,  3.7530e-02,  1.1677e-01,\n",
      "          2.9617e-01,  1.8855e-01,  9.4843e-04, -3.5803e-01,  4.9280e-01,\n",
      "          1.0813e-01, -4.4745e-01],\n",
      "        [ 1.0373e-01,  2.7608e-01,  1.6789e-01,  4.3458e-01, -1.7532e-01,\n",
      "          1.9619e-02, -1.2935e-01, -4.1903e-02,  5.9384e-02,  3.1299e-01,\n",
      "         -6.8205e-02, -3.7107e-01],\n",
      "        [ 3.4157e-01,  1.8833e-02,  2.0147e-01,  1.5313e-01, -1.7792e-01,\n",
      "         -1.7459e-01,  1.8677e-01, -2.0571e-01,  3.1410e-01, -2.9634e-01,\n",
      "         -8.3500e-02,  6.8835e-02]], requires_grad=True)\n",
      "27 blocks.1.mlp.fc2.bias Parameter containing:\n",
      "tensor([ 0.2923,  0.3282, -0.3172,  0.2755, -0.1191, -0.0761,  0.2122, -0.3247,\n",
      "        -0.3219, -0.2904,  0.1832,  0.0571,  0.0512,  0.1335,  0.1832, -0.0613,\n",
      "        -0.1686, -0.4225, -0.1915,  0.0985,  0.2355,  0.0797, -0.1166,  0.1388,\n",
      "         0.0844,  0.5802,  0.1801, -0.1515,  0.0328, -0.0606, -0.0669, -0.2719],\n",
      "       requires_grad=True)\n",
      "28 norm.weight Parameter containing:\n",
      "tensor([1.7747, 1.4917, 1.6197, 1.5779, 1.5104, 1.4884, 1.5362, 1.3611, 1.4187,\n",
      "        1.7078, 1.6985, 1.6390, 1.4516, 1.6100, 1.4507, 1.4646, 1.5929, 1.5293,\n",
      "        1.3137, 1.5417, 1.4824, 1.4481, 1.5802, 1.3600, 1.5619, 1.3735, 1.5717,\n",
      "        1.5012, 1.4898, 1.3854, 1.7713, 1.2873], requires_grad=True)\n",
      "29 norm.bias Parameter containing:\n",
      "tensor([ 0.0203,  0.0383, -0.0213, -0.2340,  0.0333,  0.0502, -0.0243,  0.0808,\n",
      "        -0.0048,  0.2621,  0.1291,  0.0696, -0.0877, -0.0033,  0.0926, -0.1714,\n",
      "         0.0946,  0.0818,  0.2862,  0.0676, -0.0495,  0.0817, -0.0908,  0.0032,\n",
      "        -0.0576, -0.2079,  0.0078,  0.1514,  0.0609, -0.0881, -0.0688, -0.0171],\n",
      "       requires_grad=True)\n",
      "30 head.weight Parameter containing:\n",
      "tensor([[-7.0662e-02,  1.3499e-01, -3.8009e-01,  6.0584e-01,  4.1917e-01,\n",
      "         -3.7075e-01,  2.0450e-01, -4.0412e-01,  6.2776e-02, -4.6475e-01,\n",
      "         -5.9376e-01, -2.4132e-01, -4.2393e-01,  1.8389e-01,  1.8460e-01,\n",
      "          2.1956e-01, -3.1886e-01, -3.3674e-01,  8.8356e-02, -4.2352e-01,\n",
      "         -4.0939e-02, -1.0542e-01,  1.8793e-01, -7.2534e-02,  1.6244e-01,\n",
      "         -1.2656e-01,  3.3465e-01,  8.5337e-02,  5.2124e-01, -3.7563e-01,\n",
      "         -4.5943e-01,  1.7528e-01],\n",
      "        [ 3.0352e-02, -5.3761e-01,  5.1218e-01,  5.0710e-01, -1.9978e-01,\n",
      "          1.8169e-01,  2.8051e-01, -2.8327e-04,  1.3403e-01,  3.0515e-01,\n",
      "         -1.6733e-01, -1.4994e-01, -2.9695e-01, -4.3653e-02, -2.0136e-01,\n",
      "         -3.6033e-01,  3.7734e-01,  7.5984e-01, -3.7332e-01,  2.5667e-01,\n",
      "         -2.6232e-01, -1.7522e-01, -3.5150e-01, -4.4539e-02,  3.4139e-02,\n",
      "          2.3827e-01,  3.2483e-01, -4.8200e-01, -3.3107e-01,  6.6220e-04,\n",
      "         -1.3452e-01, -4.9982e-03],\n",
      "        [-1.8054e-01, -3.1714e-01,  4.3834e-02, -1.5373e-01,  4.0802e-01,\n",
      "          3.0738e-01, -1.2508e-01,  2.7700e-01,  4.3899e-01,  5.5846e-01,\n",
      "          2.1806e-01, -9.6559e-02, -2.9435e-01,  8.5169e-02,  3.8948e-01,\n",
      "         -3.4951e-01,  2.4702e-01, -1.7520e-01, -2.9415e-03, -4.1315e-02,\n",
      "          2.3549e-01,  2.4263e-01, -5.3219e-01,  4.3015e-01,  3.5472e-01,\n",
      "         -1.2378e-01,  3.5077e-01, -2.0200e-01,  3.4359e-01, -6.6013e-01,\n",
      "         -5.8778e-01, -1.6139e-01],\n",
      "        [-2.9198e-01, -2.7329e-01,  1.5756e-01, -2.4867e-01,  8.9417e-02,\n",
      "          2.3414e-01, -2.4737e-01,  2.3148e-01,  2.1705e-01, -3.7169e-01,\n",
      "          2.6820e-01,  4.5165e-01,  4.8011e-01, -2.7147e-01,  3.6934e-01,\n",
      "         -4.0749e-01, -2.0289e-01, -5.9938e-02, -2.7835e-01, -1.2312e-01,\n",
      "          2.2346e-01, -4.6082e-01,  3.0568e-01,  3.6012e-01, -3.5758e-01,\n",
      "          1.2761e-01,  2.2901e-01, -2.3909e-01, -2.1400e-01,  3.9785e-02,\n",
      "          3.6608e-01, -2.2432e-01],\n",
      "        [ 3.1808e-01,  1.6361e-01, -5.3151e-01, -5.7490e-02, -3.4209e-01,\n",
      "         -7.1168e-02,  5.5124e-01, -3.6624e-01, -2.8539e-01,  2.5833e-01,\n",
      "          6.3101e-02,  1.8964e-01,  3.0680e-01,  2.6596e-01, -2.7185e-01,\n",
      "          3.1318e-01,  4.3693e-01,  3.1748e-01, -3.4351e-02, -5.3779e-02,\n",
      "         -4.4899e-01,  1.4710e-01, -7.2955e-02, -2.7403e-01, -3.3528e-01,\n",
      "         -3.3355e-01, -3.8520e-01,  3.3776e-01, -6.9318e-02,  1.5690e-01,\n",
      "         -5.4700e-01, -4.0055e-01],\n",
      "        [-3.8485e-01,  3.2392e-01,  2.1606e-01, -3.4132e-01, -5.2945e-02,\n",
      "         -5.6807e-01, -2.9394e-01,  2.3735e-01, -1.6277e-01, -3.1090e-01,\n",
      "         -4.7150e-01, -3.2620e-01,  8.1708e-02, -4.2242e-01, -3.4786e-03,\n",
      "          1.9497e-01, -3.2167e-01, -1.3660e-01, -8.5525e-02,  2.2041e-01,\n",
      "          3.6731e-01, -4.0298e-01,  1.4728e-01,  2.2276e-01,  1.1586e-01,\n",
      "          1.2572e-01, -5.0553e-02,  5.2880e-01, -3.1495e-01,  1.2935e-01,\n",
      "          4.0558e-01,  3.3001e-01],\n",
      "        [-2.7471e-01,  3.1913e-01,  2.7833e-01,  2.6196e-01,  3.4191e-01,\n",
      "         -5.6097e-01,  3.9589e-01, -2.6129e-02,  2.1695e-01,  9.3651e-02,\n",
      "         -6.9874e-01, -3.6346e-01, -3.9845e-01,  5.5253e-01,  1.0878e-01,\n",
      "          2.4859e-01,  3.0128e-01, -1.4754e-01, -2.5752e-01,  6.2928e-01,\n",
      "         -1.2901e-02, -1.0364e-01,  2.1258e-01,  1.9568e-01,  3.0191e-01,\n",
      "         -4.2708e-01, -5.5330e-01, -1.3913e-01,  5.6179e-01,  1.1965e-01,\n",
      "          1.4981e-02, -1.4524e-01],\n",
      "        [ 6.8941e-01, -2.3531e-01, -1.9712e-01, -2.2538e-02, -2.9447e-01,\n",
      "          2.4514e-01, -2.2437e-02,  3.3288e-01,  4.3496e-01, -4.7282e-02,\n",
      "          3.1498e-01,  4.1810e-01, -6.2002e-03, -1.7665e-01, -5.3883e-01,\n",
      "         -3.0075e-01,  5.1350e-01, -1.6667e-01,  3.8576e-01, -3.5322e-01,\n",
      "          2.3290e-01,  3.5336e-01, -5.1978e-01, -3.4039e-01, -4.4580e-01,\n",
      "          2.7498e-01,  2.7252e-01, -2.1813e-01, -8.3805e-02, -4.2938e-01,\n",
      "          1.6631e-01,  2.2453e-01],\n",
      "        [-2.0935e-01,  7.5188e-02, -1.6132e-02, -2.5073e-01,  3.9894e-01,\n",
      "          1.8144e-01, -3.3273e-01, -2.6652e-01, -1.4211e-01,  3.2640e-01,\n",
      "          2.1024e-01, -3.3081e-01,  2.3006e-01,  3.0565e-01, -3.5059e-01,\n",
      "          3.4438e-02, -2.6455e-01, -3.5111e-01,  3.1036e-01,  6.9776e-02,\n",
      "         -3.1493e-01, -1.5650e-01,  7.8121e-02, -2.2023e-01,  3.2235e-01,\n",
      "          5.1366e-02,  1.8662e-01, -2.7377e-01, -1.4956e-01,  1.8010e-01,\n",
      "          3.3583e-02, -1.8554e-01],\n",
      "        [ 3.4102e-01,  2.5776e-01, -1.2326e-01, -1.3406e-01, -2.0269e-01,\n",
      "          8.1846e-02,  2.9824e-01, -3.0876e-01, -3.2759e-01,  1.4421e-01,\n",
      "          2.4605e-01,  1.5572e-01,  8.5378e-02, -3.1285e-01,  1.3058e-01,\n",
      "          1.4342e-01, -2.2370e-01, -6.7050e-02,  3.7010e-01, -3.9500e-01,\n",
      "          1.1542e-02,  2.5621e-01,  2.8539e-01, -1.1901e-01, -4.4891e-01,\n",
      "         -2.8812e-01, -2.7159e-01, -1.0295e-01, -2.0197e-01,  3.1497e-01,\n",
      "          3.1011e-01,  3.1235e-01]], requires_grad=True)\n",
      "31 head.bias Parameter containing:\n",
      "tensor([-0.1678, -0.0190,  0.0916,  0.0227, -0.0017,  0.0028, -0.0895, -0.0904,\n",
      "         0.1494,  0.2000], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for i, (name, param) in enumerate(model_int8.named_parameters()):\n",
    "    print(i, name,param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FakeQuantize(\n",
       "  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.]), zero_point=tensor([0], dtype=torch.int32)\n",
       "  (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ao.quantization.fake_quantize.FakeQuantize(quant_min = 0, quant_max=2**7-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QuantStub(\n",
       "  (qconfig): FakeQuantize(\n",
       "    fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.]), zero_point=tensor([0], dtype=torch.int32)\n",
       "    (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.quantization.QuantStub(torch.ao.quantization.fake_quantize.FakeQuantize(quant_min = 0, quant_max=2**8-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QuantStub(\n",
       "  (qconfig): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       ")"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.quantization.QuantStub(torch.ao.quantization.observer.MinMaxObserver())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ao.quantization.default_qconfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_bit_length = 8\n",
    "custom_config = torch.ao.quantization.QConfig(\n",
    "    activation=torch.ao.quantization.fake_quantize.FakeQuantize.with_args(quant_max=2**max_bit_length-1, dtype=torch.quint8),  # Use HistogramObserver for activations\n",
    "    weight=torch.ao.quantization.fake_quantize.FakeQuantize.with_args(quant_max=2**max_bit_length-1, dtype=torch.quint8)  # Keep the default observer for weights (can be changed too)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2**max_bit_length-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ao.quantization.default_observer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FakeQuantize'>, quant_max=255, dtype=torch.quint8){}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FakeQuantize'>, quant_max=255, dtype=torch.quint8){})"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QConfig(activation=functools.partial(<class 'torch.ao.quantization.fake_quantize.FakeQuantize'>, quant_max=1237940039285380274899124223, dtype=torch.quint8){}, weight=functools.partial(<class 'torch.ao.quantization.fake_quantize.FakeQuantize'>, quant_max=1237940039285380274899124223, dtype=torch.quint8){})"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "My_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
